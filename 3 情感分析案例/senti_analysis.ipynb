{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io,os, random, operator, sys\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些功能函数\n",
    "需要阅读这些函数来对实验中用到的数据结构，步骤有一些理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotProduct(d1, d2):\n",
    "    \"\"\"\n",
    "    @param dict d1: a feature vector represented by a mapping from a feature (string) to a weight (float).\n",
    "    @param dict d2: same as d1\n",
    "    @return float: the dot product between d1 and d2\n",
    "    \"\"\"\n",
    "    if len(d1) < len(d2):\n",
    "        return dotProduct(d2, d1)\n",
    "    else:\n",
    "        return sum(d1.get(f, 0) * v for f, v in d2.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment(d1, scale, d2):\n",
    "    \"\"\"\n",
    "    Implements d1 += scale * d2 for sparse vectors.\n",
    "    @param dict d1: the feature vector which is mutated.\n",
    "    @param float scale\n",
    "    @param dict d2: a feature vector.\n",
    "    \"\"\"\n",
    "    for f, v in d2.items():\n",
    "        d1[f] = d1.get(f, 0) + v * scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readExamples(path):\n",
    "    '''\n",
    "    读取数据\n",
    "    '''\n",
    "    examples = []\n",
    "    for line in open(path, encoding = \"ISO-8859-1\"):\n",
    "        # Format of each line: <output label (+1 or -1)> <input sentence>\n",
    "        y, x = line.split(' ', 1)\n",
    "        examples.append((x.strip(), int(y)))\n",
    "    print('Read %d examples from %s' % (len(examples), path))\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePredictor(examples, predictor):\n",
    "    '''\n",
    "    在|examples|上测试|predictor|的性能，返回错误率\n",
    "    '''\n",
    "    error = 0\n",
    "    for x, y in examples:\n",
    "        if predictor(x) != y:\n",
    "            error += 1\n",
    "    return 1.0 * error / len(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extrator (Your codes here)\n",
    "\n",
    "### (1) 使用BOW作为特征\n",
    "(a) 复习BOW\n",
    "(b) 如何把一个句子（字符串）转化成BOW的特征？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_bow(x):\n",
    "    features = collections.defaultdict(float)\n",
    "    for word in x.split():\n",
    "        features[word] += 1.0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 使用N-Gram作为特征\n",
    "(a) 复习N-Gram相关的内容\n",
    "(b) 字级别N-Gram还是词语级别？\n",
    "(c) 如何把一个句子（字符串）转化成N-Gram的特征？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_ngram(x, n=2):\n",
    "    features = collections.defaultdict(float)\n",
    "    words = x.split()\n",
    "    for i in range(len(words) - n + 1):\n",
    "        ngram = ' '.join(words[i:i+n])\n",
    "        features[ngram] += 1.0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （3） 使用word2vec作为特征\n",
    "(a) 获得词向量。你可以借鉴第一次的作业，使用gensim来自己训练一个word2vec, 或者加载预训练过的word2vec(gensim的网站上有说明如何下载并使用预训练过的词向量)。\n",
    "(b) 考虑如何使用词向量得到句子的表示向量（feature）。\n",
    "(c) 将向量转化为其余部分可以处理的形式（如：dict）\n",
    "(d) 考虑如何**更好地**使用词向量得到句子的表示向量（feature）。\n",
    "\n",
    "提示: 在ipynb的代码块中可以使用! 来执行命令行中的命令, 例如\n",
    "```\n",
    "!pip install gensim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用预训练的word2vec模型(FastText Word Embeddings)加载词向量 \n",
    "\n",
    "def loadWord2VecModel(filename):\n",
    "    wordVectors = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            wordVectors[word] = vector\n",
    "    return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_news= './data/wiki-news-300d-1M.vec'\n",
    "wordVectors = loadWord2VecModel(wiki_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_wordvec(x):\n",
    "    # 将句子x拆分成单个字符或单词\n",
    "    tokens = x.split()\n",
    "    # 句子的词向量表示\n",
    "    vectors = [wordVectors[token] for token in tokens if token in wordVectors.keys()]\n",
    "    # 将句子中的每个单词转换为对应的词向量，然后将这些词向量的平均值作为该句子的特征向量\n",
    "    if vectors:\n",
    "        # 将句子中的每个单词转换为对应的词向量，然后将这些词向量的平均值作为该句子的特征向量\n",
    "        vectors = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # 处理句子中所有单词都不在模型中的情况\n",
    "        vectors = np.zeros(len(next(iter(wordVectors.values()))))\n",
    "    # 将特征向量表示为字典\n",
    "    featureDict = {}\n",
    "    for i, value in enumerate(vectors):\n",
    "        featureDict[f'feature_{i}'] = value\n",
    "    \n",
    "    return featureDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Test your feature extractor\n",
    "实现了特征提取函数之后，可以简单地测试输出的正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'a': 1.0,\n",
       "             'truly': 1.0,\n",
       "             'wonderful': 1.0,\n",
       "             'tale': 1.0,\n",
       "             'combined': 1.0,\n",
       "             'with': 1.0,\n",
       "             'stunning': 1.0,\n",
       "             'animation': 1.0,\n",
       "             '.': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"a truly wonderful tale combined with stunning animation .\"\n",
    "extractFeatures_bow(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'a truly': 1.0,\n",
       "             'truly wonderful': 1.0,\n",
       "             'wonderful tale': 1.0,\n",
       "             'tale combined': 1.0,\n",
       "             'combined with': 1.0,\n",
       "             'with stunning': 1.0,\n",
       "             'stunning animation': 1.0,\n",
       "             'animation .': 1.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractFeatures_ngram(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_0': -0.015788889,\n",
       " 'feature_1': -0.031044444,\n",
       " 'feature_2': -0.037788887,\n",
       " 'feature_3': -0.022766666,\n",
       " 'feature_4': 0.008255554,\n",
       " 'feature_5': -0.04491111,\n",
       " 'feature_6': -0.0072111106,\n",
       " 'feature_7': -0.0014666673,\n",
       " 'feature_8': -0.016855557,\n",
       " 'feature_9': 0.008622223,\n",
       " 'feature_10': -0.015466667,\n",
       " 'feature_11': -0.033733334,\n",
       " 'feature_12': -0.0752,\n",
       " 'feature_13': -0.029000001,\n",
       " 'feature_14': 0.05194444,\n",
       " 'feature_15': -0.0050777774,\n",
       " 'feature_16': 0.03831111,\n",
       " 'feature_17': -0.036411114,\n",
       " 'feature_18': -0.052144445,\n",
       " 'feature_19': -0.01168889,\n",
       " 'feature_20': -0.05437778,\n",
       " 'feature_21': 0.026044445,\n",
       " 'feature_22': 0.018011112,\n",
       " 'feature_23': 0.051777776,\n",
       " 'feature_24': 0.0025777784,\n",
       " 'feature_25': -0.0508,\n",
       " 'feature_26': 0.014877778,\n",
       " 'feature_27': -0.052522223,\n",
       " 'feature_28': 0.0066111083,\n",
       " 'feature_29': -0.024466665,\n",
       " 'feature_30': -0.013599998,\n",
       " 'feature_31': -0.023655554,\n",
       " 'feature_32': 0.051422223,\n",
       " 'feature_33': -0.016577778,\n",
       " 'feature_34': 0.060577776,\n",
       " 'feature_35': 0.00012222388,\n",
       " 'feature_36': 0.023655556,\n",
       " 'feature_37': 0.0005222228,\n",
       " 'feature_38': 0.063888885,\n",
       " 'feature_39': -0.01234445,\n",
       " 'feature_40': 0.06515555,\n",
       " 'feature_41': -0.015077778,\n",
       " 'feature_42': 0.028577778,\n",
       " 'feature_43': -0.055300005,\n",
       " 'feature_44': -0.018855555,\n",
       " 'feature_45': -0.011133332,\n",
       " 'feature_46': 0.026399998,\n",
       " 'feature_47': -0.008111111,\n",
       " 'feature_48': -0.05152222,\n",
       " 'feature_49': -0.016177779,\n",
       " 'feature_50': -0.016566668,\n",
       " 'feature_51': -0.018366667,\n",
       " 'feature_52': -0.64422226,\n",
       " 'feature_53': 0.0328,\n",
       " 'feature_54': -0.022088889,\n",
       " 'feature_55': -0.038911115,\n",
       " 'feature_56': -0.059499998,\n",
       " 'feature_57': 0.05397778,\n",
       " 'feature_58': -0.03714444,\n",
       " 'feature_59': 0.03398889,\n",
       " 'feature_60': 0.06916667,\n",
       " 'feature_61': -0.0005999992,\n",
       " 'feature_62': 0.06766667,\n",
       " 'feature_63': -0.01818889,\n",
       " 'feature_64': -0.03765555,\n",
       " 'feature_65': -0.08047778,\n",
       " 'feature_66': 0.015311111,\n",
       " 'feature_67': -0.029844442,\n",
       " 'feature_68': -0.008022221,\n",
       " 'feature_69': 0.038011108,\n",
       " 'feature_70': -0.0025777789,\n",
       " 'feature_71': 0.0455,\n",
       " 'feature_72': 0.0122,\n",
       " 'feature_73': -0.01098889,\n",
       " 'feature_74': 0.049188893,\n",
       " 'feature_75': -2.2220529e-05,\n",
       " 'feature_76': 0.026033334,\n",
       " 'feature_77': -0.012022221,\n",
       " 'feature_78': -0.05022222,\n",
       " 'feature_79': 0.036844444,\n",
       " 'feature_80': 0.01821111,\n",
       " 'feature_81': 0.011377777,\n",
       " 'feature_82': -0.013677776,\n",
       " 'feature_83': -0.19941111,\n",
       " 'feature_84': 0.03392222,\n",
       " 'feature_85': 0.028077781,\n",
       " 'feature_86': 0.05377778,\n",
       " 'feature_87': -0.021100001,\n",
       " 'feature_88': -0.008944443,\n",
       " 'feature_89': -0.057800002,\n",
       " 'feature_90': 0.011744444,\n",
       " 'feature_91': 0.0047555547,\n",
       " 'feature_92': -0.048544444,\n",
       " 'feature_93': 0.004655556,\n",
       " 'feature_94': -0.025922224,\n",
       " 'feature_95': -0.08494444,\n",
       " 'feature_96': -0.034988888,\n",
       " 'feature_97': -0.0024111106,\n",
       " 'feature_98': 0.015266667,\n",
       " 'feature_99': 0.026133334,\n",
       " 'feature_100': -0.1712111,\n",
       " 'feature_101': -0.05591111,\n",
       " 'feature_102': -0.0069222217,\n",
       " 'feature_103': 0.0028444421,\n",
       " 'feature_104': -0.099922225,\n",
       " 'feature_105': -0.019055555,\n",
       " 'feature_106': 0.0719111,\n",
       " 'feature_107': -0.0059888884,\n",
       " 'feature_108': 0.0731,\n",
       " 'feature_109': -0.07293333,\n",
       " 'feature_110': 0.009433331,\n",
       " 'feature_111': -0.050555557,\n",
       " 'feature_112': 0.0122444425,\n",
       " 'feature_113': -0.019522222,\n",
       " 'feature_114': 4.444499e-05,\n",
       " 'feature_115': -0.031999998,\n",
       " 'feature_116': 0.003788889,\n",
       " 'feature_117': -0.054733336,\n",
       " 'feature_118': -0.028633334,\n",
       " 'feature_119': -0.29747775,\n",
       " 'feature_120': -0.02992222,\n",
       " 'feature_121': -0.07523333,\n",
       " 'feature_122': 0.0017888894,\n",
       " 'feature_123': 0.04401111,\n",
       " 'feature_124': -0.047055557,\n",
       " 'feature_125': 0.17301111,\n",
       " 'feature_126': -0.029555555,\n",
       " 'feature_127': 0.017944446,\n",
       " 'feature_128': -0.029777778,\n",
       " 'feature_129': 0.028633334,\n",
       " 'feature_130': -0.019199999,\n",
       " 'feature_131': 0.04002222,\n",
       " 'feature_132': -0.013566665,\n",
       " 'feature_133': -0.027122222,\n",
       " 'feature_134': 0.0037222223,\n",
       " 'feature_135': -0.1919889,\n",
       " 'feature_136': 0.019211112,\n",
       " 'feature_137': 0.0748,\n",
       " 'feature_138': 0.004866666,\n",
       " 'feature_139': -0.024833335,\n",
       " 'feature_140': -0.00461111,\n",
       " 'feature_141': -0.029688887,\n",
       " 'feature_142': -0.0041000005,\n",
       " 'feature_143': 0.18965556,\n",
       " 'feature_144': 0.024222221,\n",
       " 'feature_145': -0.010233333,\n",
       " 'feature_146': 0.076177776,\n",
       " 'feature_147': -0.043111112,\n",
       " 'feature_148': 0.057144444,\n",
       " 'feature_149': -0.002211112,\n",
       " 'feature_150': -0.017499998,\n",
       " 'feature_151': 0.023655556,\n",
       " 'feature_152': -0.040288888,\n",
       " 'feature_153': -0.07016666,\n",
       " 'feature_154': 0.05212222,\n",
       " 'feature_155': 0.057133336,\n",
       " 'feature_156': -0.05794445,\n",
       " 'feature_157': 0.013088888,\n",
       " 'feature_158': 0.0140333325,\n",
       " 'feature_159': -0.016822223,\n",
       " 'feature_160': -0.016822223,\n",
       " 'feature_161': 0.0056999996,\n",
       " 'feature_162': 0.0283,\n",
       " 'feature_163': 0.058522224,\n",
       " 'feature_164': -0.035988886,\n",
       " 'feature_165': 0.029877778,\n",
       " 'feature_166': 0.07563333,\n",
       " 'feature_167': 0.008955555,\n",
       " 'feature_168': 0.021033334,\n",
       " 'feature_169': -0.03903333,\n",
       " 'feature_170': 0.014266668,\n",
       " 'feature_171': -0.016066667,\n",
       " 'feature_172': -0.038155556,\n",
       " 'feature_173': 0.024688888,\n",
       " 'feature_174': 0.07422222,\n",
       " 'feature_175': -0.036788892,\n",
       " 'feature_176': 0.17065555,\n",
       " 'feature_177': -0.1497111,\n",
       " 'feature_178': -0.026222222,\n",
       " 'feature_179': -0.010155555,\n",
       " 'feature_180': -0.012622221,\n",
       " 'feature_181': 0.0344,\n",
       " 'feature_182': -0.044377778,\n",
       " 'feature_183': 0.03595556,\n",
       " 'feature_184': 0.07063333,\n",
       " 'feature_185': 0.035122223,\n",
       " 'feature_186': 0.015333333,\n",
       " 'feature_187': -0.00993333,\n",
       " 'feature_188': 0.13093334,\n",
       " 'feature_189': 0.043733332,\n",
       " 'feature_190': -0.036644444,\n",
       " 'feature_191': -0.020399997,\n",
       " 'feature_192': -0.017022222,\n",
       " 'feature_193': 0.043455556,\n",
       " 'feature_194': 0.0074666655,\n",
       " 'feature_195': 0.054177776,\n",
       " 'feature_196': -0.013177777,\n",
       " 'feature_197': 0.025688892,\n",
       " 'feature_198': 0.18443333,\n",
       " 'feature_199': -0.015233333,\n",
       " 'feature_200': 0.016288888,\n",
       " 'feature_201': -0.015744444,\n",
       " 'feature_202': -0.024988888,\n",
       " 'feature_203': -0.030199997,\n",
       " 'feature_204': 0.06804445,\n",
       " 'feature_205': 0.0012222222,\n",
       " 'feature_206': -0.03001111,\n",
       " 'feature_207': -0.0726889,\n",
       " 'feature_208': -0.034877777,\n",
       " 'feature_209': 0.079166666,\n",
       " 'feature_210': 0.05288889,\n",
       " 'feature_211': -0.0216,\n",
       " 'feature_212': -0.026422221,\n",
       " 'feature_213': -0.014588889,\n",
       " 'feature_214': -0.015244446,\n",
       " 'feature_215': 0.000111111025,\n",
       " 'feature_216': -0.0052888882,\n",
       " 'feature_217': 0.0064999987,\n",
       " 'feature_218': -0.056333337,\n",
       " 'feature_219': 0.030011114,\n",
       " 'feature_220': 0.009622223,\n",
       " 'feature_221': -0.025600003,\n",
       " 'feature_222': 0.03666667,\n",
       " 'feature_223': 0.0064777764,\n",
       " 'feature_224': 0.030166665,\n",
       " 'feature_225': -0.05404444,\n",
       " 'feature_226': 0.009344444,\n",
       " 'feature_227': 0.02498889,\n",
       " 'feature_228': 0.0006666647,\n",
       " 'feature_229': -0.1871,\n",
       " 'feature_230': -0.008577778,\n",
       " 'feature_231': -0.009188888,\n",
       " 'feature_232': 0.31073332,\n",
       " 'feature_233': -0.0027333316,\n",
       " 'feature_234': -0.0029333332,\n",
       " 'feature_235': -0.007966667,\n",
       " 'feature_236': 0.00018888712,\n",
       " 'feature_237': -0.044877775,\n",
       " 'feature_238': -0.20561111,\n",
       " 'feature_239': -0.03897778,\n",
       " 'feature_240': -0.0136222225,\n",
       " 'feature_241': 0.02178889,\n",
       " 'feature_242': 0.045622226,\n",
       " 'feature_243': -0.00821111,\n",
       " 'feature_244': 0.01308889,\n",
       " 'feature_245': -0.02088889,\n",
       " 'feature_246': -0.019177778,\n",
       " 'feature_247': 0.064111106,\n",
       " 'feature_248': 0.019655555,\n",
       " 'feature_249': 0.34937778,\n",
       " 'feature_250': 0.043522224,\n",
       " 'feature_251': 0.03597778,\n",
       " 'feature_252': -0.048477784,\n",
       " 'feature_253': -0.015244443,\n",
       " 'feature_254': -0.031099997,\n",
       " 'feature_255': -0.00036666667,\n",
       " 'feature_256': -0.04287778,\n",
       " 'feature_257': 0.020966668,\n",
       " 'feature_258': -0.011000002,\n",
       " 'feature_259': 0.0009000001,\n",
       " 'feature_260': -0.07032222,\n",
       " 'feature_261': 0.031366665,\n",
       " 'feature_262': -0.025211113,\n",
       " 'feature_263': -0.018122222,\n",
       " 'feature_264': -0.15086667,\n",
       " 'feature_265': 0.013522223,\n",
       " 'feature_266': 0.02601111,\n",
       " 'feature_267': -0.04422222,\n",
       " 'feature_268': -0.11850001,\n",
       " 'feature_269': -0.017677777,\n",
       " 'feature_270': -0.041344445,\n",
       " 'feature_271': -0.00978889,\n",
       " 'feature_272': -0.010488889,\n",
       " 'feature_273': 0.06334445,\n",
       " 'feature_274': -0.013177779,\n",
       " 'feature_275': 0.026277777,\n",
       " 'feature_276': 0.014577778,\n",
       " 'feature_277': -0.036811113,\n",
       " 'feature_278': -0.008544443,\n",
       " 'feature_279': 0.015255554,\n",
       " 'feature_280': -0.0044666673,\n",
       " 'feature_281': 0.0023555541,\n",
       " 'feature_282': 0.02524444,\n",
       " 'feature_283': 0.014633334,\n",
       " 'feature_284': -0.024155553,\n",
       " 'feature_285': -0.028133336,\n",
       " 'feature_286': -0.027166666,\n",
       " 'feature_287': 0.016377777,\n",
       " 'feature_288': -0.021266667,\n",
       " 'feature_289': 0.052277777,\n",
       " 'feature_290': -0.013222221,\n",
       " 'feature_291': 0.010588888,\n",
       " 'feature_292': -0.027022224,\n",
       " 'feature_293': -0.0335,\n",
       " 'feature_294': 0.04242222,\n",
       " 'feature_295': -0.01256667,\n",
       " 'feature_296': 0.027177775,\n",
       " 'feature_297': 0.1596,\n",
       " 'feature_298': 0.042866666,\n",
       " 'feature_299': -0.0055666664}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractFeatures_wordvec(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习与梯度更新\n",
    "你需要理解题目中的loss_function, 自行推导出weights的更新公式，\n",
    "通过对训练集上样本的迭代，来更新weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learnPredictor(trainExamples, testExamples, featureExtractor, numIters, eta):\n",
    "    '''\n",
    "    给定训练数据和测试数据，特征提取器|featureExtractor|、训练轮数|numIters|和学习率|eta|，\n",
    "    返回学习后的权重weights\n",
    "    你需要实现随机梯度下降优化权重\n",
    "    '''\n",
    "    weights = collections.defaultdict(float)\n",
    "    for  i in range(0, numIters):\n",
    "        for example in trainExamples:\n",
    "            x, y = example\n",
    "            # 获取特征向量\n",
    "            featureVector = featureExtractor(x)\n",
    "            # 计算预测值\n",
    "            predicted = dotProduct(featureVector, weights)\n",
    "            # 计算损失\n",
    "            loss = max(0, 1 - predicted * y)\n",
    "            # 如果损失大于0，更新权重向量\n",
    "            if loss > 0:\n",
    "                # 更新权重向量\n",
    "                for feature, value in featureVector.items():\n",
    "                    weights[feature] += eta * value * y\n",
    "        trainError = evaluatePredictor(trainExamples, lambda x : (1 if dotProduct(featureExtractor(x), weights) >= 0 else -1))\n",
    "        testError= evaluatePredictor(testExamples, lambda x : (1 if dotProduct(featureExtractor(x), weights) >= 0 else -1))\n",
    "        print(\"At iteration %d, error rate on training set is  %f, error rate on test set is %f \" % \\\n",
    "            (i, trainError, testError)) \n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 已经定义好的训练测试流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(numIters, eta):\n",
    "    trainExamples = readExamples('data/data_rt.train')\n",
    "    testExamples = readExamples('data/data_rt.test')\n",
    "    featureExtractor = extractFeatures_wordvec\n",
    "    weights = learnPredictor(trainExamples, testExamples, featureExtractor, numIters=numIters, eta=eta)\n",
    "    trainError = evaluatePredictor(trainExamples, lambda x : (1 if dotProduct(featureExtractor(x), weights) >= 0 else -1))\n",
    "    testError = evaluatePredictor(testExamples, lambda x : (1 if dotProduct(featureExtractor(x), weights) >= 0 else -1))\n",
    "    print (\"train error = %s, test error = %s\" % (trainError, testError))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试你的模型!\n",
    "(a) 超参请自行更改\n",
    "(b) 自行增加代码来进行训练loss和测试loss变化图的绘制\n",
    "(b) 分析性能,模型泛化能力, 权重weights的可解释性等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 3554 examples from data/data_rt.train\n",
      "Read 3554 examples from data/data_rt.test\n",
      "At iteration 0, error rate on training set is  0.472425, error rate on test set is 0.470737 \n",
      "At iteration 1, error rate on training set is  0.440912, error rate on test set is 0.446258 \n",
      "At iteration 2, error rate on training set is  0.315419, error rate on test set is 0.321891 \n",
      "At iteration 3, error rate on training set is  0.284750, error rate on test set is 0.290377 \n",
      "At iteration 4, error rate on training set is  0.284187, error rate on test set is 0.289533 \n",
      "At iteration 5, error rate on training set is  0.280248, error rate on test set is 0.289533 \n",
      "At iteration 6, error rate on training set is  0.270400, error rate on test set is 0.278841 \n",
      "At iteration 7, error rate on training set is  0.267023, error rate on test set is 0.269555 \n",
      "At iteration 8, error rate on training set is  0.263084, error rate on test set is 0.266742 \n",
      "At iteration 9, error rate on training set is  0.258019, error rate on test set is 0.264491 \n",
      "At iteration 10, error rate on training set is  0.254924, error rate on test set is 0.262521 \n",
      "At iteration 11, error rate on training set is  0.250703, error rate on test set is 0.261958 \n",
      "At iteration 12, error rate on training set is  0.249015, error rate on test set is 0.259426 \n",
      "At iteration 13, error rate on training set is  0.244795, error rate on test set is 0.254924 \n",
      "At iteration 14, error rate on training set is  0.245639, error rate on test set is 0.254361 \n",
      "At iteration 15, error rate on training set is  0.240855, error rate on test set is 0.252954 \n",
      "At iteration 16, error rate on training set is  0.240293, error rate on test set is 0.250985 \n",
      "At iteration 17, error rate on training set is  0.238886, error rate on test set is 0.248734 \n",
      "At iteration 18, error rate on training set is  0.238604, error rate on test set is 0.249015 \n",
      "At iteration 19, error rate on training set is  0.236072, error rate on test set is 0.248171 \n",
      "At iteration 20, error rate on training set is  0.236635, error rate on test set is 0.248452 \n",
      "At iteration 21, error rate on training set is  0.235228, error rate on test set is 0.245076 \n",
      "At iteration 22, error rate on training set is  0.231851, error rate on test set is 0.242544 \n",
      "At iteration 23, error rate on training set is  0.230726, error rate on test set is 0.242544 \n",
      "At iteration 24, error rate on training set is  0.225943, error rate on test set is 0.240855 \n",
      "At iteration 25, error rate on training set is  0.224536, error rate on test set is 0.242262 \n",
      "At iteration 26, error rate on training set is  0.222566, error rate on test set is 0.240293 \n",
      "At iteration 27, error rate on training set is  0.221441, error rate on test set is 0.238042 \n",
      "At iteration 28, error rate on training set is  0.220878, error rate on test set is 0.237479 \n",
      "At iteration 29, error rate on training set is  0.220315, error rate on test set is 0.236916 \n",
      "train error = 0.22031513787281937, test error = 0.236916150815982\n"
     ]
    }
   ],
   "source": [
    "TestModel(30, 0.01)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "360e1296ec1cf693a44132c53344586757f6573cbbb9fe6fc8b93b8db91badb0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
