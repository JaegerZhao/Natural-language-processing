{"cells":[{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-06-16T14:04:48.047020Z","iopub.status.busy":"2024-06-16T14:04:48.046568Z","iopub.status.idle":"2024-06-16T14:04:48.052583Z","shell.execute_reply":"2024-06-16T14:04:48.052029Z"},"hide_input":true,"jupyter":{"source_hidden":true},"papermill":{"duration":0.102238,"end_time":"2024-06-16T14:04:48.053808","exception":false,"start_time":"2024-06-16T14:04:47.951570","status":"completed"},"tags":[],"id":"E6761FEC36F247A29FFEC22F1076DBF9","scrolled":false,"slideshow":{"slide_type":"slide"},"notebookId":"666ffc80c6683ad95982ae15","trusted":true},"source":"mountedDB = {}","outputs":[],"execution_count":1},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-06-16T14:04:48.236924Z","iopub.status.busy":"2024-06-16T14:04:48.236508Z","iopub.status.idle":"2024-06-16T14:04:58.698294Z","shell.execute_reply":"2024-06-16T14:04:58.697567Z"},"id":"CF81BAE337EB48C4BD6E1D3B455BCDC7","jupyter":{"source_hidden":true},"notebookId":"666ffc80c6683ad95982ae15","papermill":{"duration":10.55741,"end_time":"2024-06-16T14:04:58.700049","exception":false,"start_time":"2024-06-16T14:04:48.142639","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple transformers","outputs":[{"name":"stdout","output_type":"stream","text":"Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\nCollecting transformers\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d9/b7/98f821d70102e2d38483bbb7013a689d2d646daa4495377bc910374ad727/transformers-4.41.2-py3-none-any.whl (9.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nCollecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/69/d6/73f9d1b7c4da5f0544bc17680d0fa9932445423b90cd38e1ee77d001a4f5/huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nCollecting regex!=2019.12.17 (from transformers)\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/07/17/5d92509b4dccacf9767d8607112c19667e15db2428014440bae4356b8aff/regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nCollecting tokenizers<0.20,>=0.19 (from transformers)\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/4f/eb78de4af3b17b589f43a369cbf0c3a7173f25c3d2cd93068852c07689aa/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting safetensors>=0.4.1 (from transformers)\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8f/05/969e1a976b84283285181b00028cf73d78434b77a6627fc2a94194cca265/safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\nSuccessfully installed huggingface-hub-0.23.4 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.2\n"}],"execution_count":2},{"cell_type":"code","metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-06-16T14:04:59.068050Z","iopub.status.busy":"2024-06-16T14:04:59.067486Z","iopub.status.idle":"2024-06-17T08:54:02.884149Z","shell.execute_reply":"2024-06-17T08:54:02.883460Z"},"id":"4F0EA52ED092466690A04AB744AB24C2","jupyter":{"source_hidden":true},"notebookId":"666ffc80c6683ad95982ae15","papermill":{"duration":67743.92645,"end_time":"2024-06-17T08:54:02.885917","exception":false,"start_time":"2024-06-16T14:04:58.959467","status":"completed"},"scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"!python train.py --model_type bert --model_name_or_path /home/mw/input/bert3258/models--bert-base-cased/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e --prepro_data_dir /home/mw/input/nlppretrain5414/prepro_data/prepro_data --save_name my_model  --batch_size 8","outputs":[{"name":"stdout","output_type":"stream","text":"Reading testing data...\ndev\nFinish reading\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\ntot_step: 76400 save_step: 1910 4e-05\n| epoch  0 | step   50 |  ms/b 730.73 | train loss 0.87818599 | NA acc: 0.00 | not NA acc: 0.01  | tot acc: 0.00 \n| epoch  0 | step  100 |  ms/b 726.27 | train loss 0.84901958 | NA acc: 0.00 | not NA acc: 0.01  | tot acc: 0.00 \n| epoch  0 | step  150 |  ms/b 748.82 | train loss 0.80610914 | NA acc: 0.00 | not NA acc: 0.01  | tot acc: 0.00 \n| epoch  0 | step  200 |  ms/b 759.49 | train loss 0.73734613 | NA acc: 0.00 | not NA acc: 0.01  | tot acc: 0.00 \n| epoch  0 | step  250 |  ms/b 764.01 | train loss 0.62518314 | NA acc: 0.00 | not NA acc: 0.01  | tot acc: 0.00 \n| epoch  0 | step  300 |  ms/b 771.34 | train loss 0.37357129 | NA acc: 0.00 | not NA acc: 0.01  | tot acc: 0.01 \n| epoch  0 | step  350 |  ms/b 785.81 | train loss 0.09805263 | NA acc: 0.08 | not NA acc: 0.01  | tot acc: 0.06 \n| epoch  1 | step  400 |  ms/b 777.52 | train loss 0.04371562 | NA acc: 0.94 | not NA acc: 0.05  | tot acc: 0.64 \n| epoch  1 | step  450 |  ms/b 783.31 | train loss 0.03945215 | NA acc: 0.96 | not NA acc: 0.04  | tot acc: 0.65 \n| epoch  1 | step  500 |  ms/b 784.87 | train loss 0.03836270 | NA acc: 0.97 | not NA acc: 0.05  | tot acc: 0.66 \n| epoch  1 | step  550 |  ms/b 786.95 | train loss 0.03402300 | NA acc: 0.97 | not NA acc: 0.06  | tot acc: 0.66 \n| epoch  1 | step  600 |  ms/b 784.36 | train loss 0.03405657 | NA acc: 0.97 | not NA acc: 0.08  | tot acc: 0.67 \n| epoch  1 | step  650 |  ms/b 784.19 | train loss 0.03005883 | NA acc: 0.97 | not NA acc: 0.10  | tot acc: 0.68 \n| epoch  1 | step  700 |  ms/b 786.46 | train loss 0.02883239 | NA acc: 0.97 | not NA acc: 0.12  | tot acc: 0.68 \n| epoch  1 | step  750 |  ms/b 783.17 | train loss 0.03034796 | NA acc: 0.96 | not NA acc: 0.14  | tot acc: 0.68 \n| epoch  2 | step  800 |  ms/b 778.94 | train loss 0.02713779 | NA acc: 0.95 | not NA acc: 0.29  | tot acc: 0.70 \n| epoch  2 | step  850 |  ms/b 791.33 | train loss 0.02438657 | NA acc: 0.95 | not NA acc: 0.30  | tot acc: 0.73 \n| epoch  2 | step  900 |  ms/b 787.65 | train loss 0.02548595 | NA acc: 0.95 | not NA acc: 0.31  | tot acc: 0.73 \n| epoch  2 | step  950 |  ms/b 793.79 | train loss 0.02081329 | NA acc: 0.95 | not NA acc: 0.32  | tot acc: 0.74 \n| epoch  2 | step 1000 |  ms/b 794.54 | train loss 0.02020603 | NA acc: 0.95 | not NA acc: 0.33  | tot acc: 0.75 \n| epoch  2 | step 1050 |  ms/b 787.08 | train loss 0.02209049 | NA acc: 0.95 | not NA acc: 0.35  | tot acc: 0.75 \n| epoch  2 | step 1100 |  ms/b 789.67 | train loss 0.01989415 | NA acc: 0.95 | not NA acc: 0.36  | tot acc: 0.75 \n| epoch  3 | step 1150 |  ms/b 777.99 | train loss 0.01929246 | NA acc: 0.97 | not NA acc: 0.39  | tot acc: 0.79 \n| epoch  3 | step 1200 |  ms/b 780.58 | train loss 0.01873577 | NA acc: 0.94 | not NA acc: 0.47  | tot acc: 0.77 \n| epoch  3 | step 1250 |  ms/b 785.24 | train loss 0.01613749 | NA acc: 0.94 | not NA acc: 0.49  | tot acc: 0.78 \n| epoch  3 | step 1300 |  ms/b 788.16 | train loss 0.01640227 | NA acc: 0.94 | not NA acc: 0.49  | tot acc: 0.79 \n| epoch  3 | step 1350 |  ms/b 791.57 | train loss 0.01688204 | NA acc: 0.94 | not NA acc: 0.49  | tot acc: 0.79 \n| epoch  3 | step 1400 |  ms/b 791.64 | train loss 0.01683768 | NA acc: 0.94 | not NA acc: 0.50  | tot acc: 0.79 \n| epoch  3 | step 1450 |  ms/b 792.89 | train loss 0.01423776 | NA acc: 0.94 | not NA acc: 0.51  | tot acc: 0.80 \n| epoch  3 | step 1500 |  ms/b 781.78 | train loss 0.01535564 | NA acc: 0.94 | not NA acc: 0.52  | tot acc: 0.80 \n| epoch  4 | step 1550 |  ms/b 778.95 | train loss 0.01548614 | NA acc: 0.92 | not NA acc: 0.60  | tot acc: 0.80 \n| epoch  4 | step 1600 |  ms/b 794.66 | train loss 0.01242825 | NA acc: 0.94 | not NA acc: 0.60  | tot acc: 0.83 \n| epoch  4 | step 1650 |  ms/b 788.49 | train loss 0.01322954 | NA acc: 0.94 | not NA acc: 0.60  | tot acc: 0.83 \n| epoch  4 | step 1700 |  ms/b 789.28 | train loss 0.01294647 | NA acc: 0.94 | not NA acc: 0.61  | tot acc: 0.83 \n| epoch  4 | step 1750 |  ms/b 784.60 | train loss 0.01255892 | NA acc: 0.94 | not NA acc: 0.61  | tot acc: 0.83 \n| epoch  4 | step 1800 |  ms/b 790.19 | train loss 0.01297596 | NA acc: 0.94 | not NA acc: 0.61  | tot acc: 0.83 \n| epoch  4 | step 1850 |  ms/b 792.04 | train loss 0.01146293 | NA acc: 0.94 | not NA acc: 0.61  | tot acc: 0.83 \n| epoch  4 | step 1900 |  ms/b 784.50 | train loss 0.01129617 | NA acc: 0.94 | not NA acc: 0.62  | tot acc: 0.83 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 77.87\ntotal_recall 12323\npredicted as zero 354790\ntotal ins num 395726\ntop1_acc 8249\nALL  : Theta 0.8800 | F1 0.4293 | AUC 0.3783\nIgnore ma_f1 0.4081 | input_theta 0.8800 test_result F1 0.4080 | AUC 0.3515\n| epoch   4 | time: 193.47s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch  5 | step 1950 |  ms/b 4630.94 | train loss 0.01044386 | NA acc: 0.93 | not NA acc: 0.70  | tot acc: 0.85 \n| epoch  5 | step 2000 |  ms/b 746.59 | train loss 0.01079822 | NA acc: 0.94 | not NA acc: 0.70  | tot acc: 0.85 \n| epoch  5 | step 2050 |  ms/b 759.65 | train loss 0.01003719 | NA acc: 0.94 | not NA acc: 0.69  | tot acc: 0.85 \n| epoch  5 | step 2100 |  ms/b 771.44 | train loss 0.00947864 | NA acc: 0.94 | not NA acc: 0.69  | tot acc: 0.85 \n| epoch  5 | step 2150 |  ms/b 782.93 | train loss 0.00978423 | NA acc: 0.94 | not NA acc: 0.69  | tot acc: 0.86 \n| epoch  5 | step 2200 |  ms/b 783.13 | train loss 0.01016473 | NA acc: 0.94 | not NA acc: 0.69  | tot acc: 0.86 \n| epoch  5 | step 2250 |  ms/b 778.60 | train loss 0.01016811 | NA acc: 0.94 | not NA acc: 0.69  | tot acc: 0.86 \n| epoch  6 | step 2300 |  ms/b 781.69 | train loss 0.00928835 | NA acc: 0.91 | not NA acc: 0.77  | tot acc: 0.86 \n| epoch  6 | step 2350 |  ms/b 788.21 | train loss 0.00791420 | NA acc: 0.94 | not NA acc: 0.74  | tot acc: 0.88 \n| epoch  6 | step 2400 |  ms/b 783.74 | train loss 0.00853015 | NA acc: 0.94 | not NA acc: 0.75  | tot acc: 0.88 \n| epoch  6 | step 2450 |  ms/b 787.36 | train loss 0.00872371 | NA acc: 0.94 | not NA acc: 0.74  | tot acc: 0.87 \n| epoch  6 | step 2500 |  ms/b 782.30 | train loss 0.00925156 | NA acc: 0.94 | not NA acc: 0.75  | tot acc: 0.87 \n| epoch  6 | step 2550 |  ms/b 783.77 | train loss 0.00885909 | NA acc: 0.94 | not NA acc: 0.75  | tot acc: 0.87 \n| epoch  6 | step 2600 |  ms/b 779.84 | train loss 0.00906577 | NA acc: 0.94 | not NA acc: 0.75  | tot acc: 0.87 \n| epoch  6 | step 2650 |  ms/b 785.81 | train loss 0.00833111 | NA acc: 0.94 | not NA acc: 0.74  | tot acc: 0.87 \n| epoch  7 | step 2700 |  ms/b 780.08 | train loss 0.00772560 | NA acc: 0.95 | not NA acc: 0.77  | tot acc: 0.89 \n| epoch  7 | step 2750 |  ms/b 788.25 | train loss 0.00727666 | NA acc: 0.94 | not NA acc: 0.77  | tot acc: 0.89 \n| epoch  7 | step 2800 |  ms/b 782.53 | train loss 0.00772325 | NA acc: 0.94 | not NA acc: 0.77  | tot acc: 0.89 \n| epoch  7 | step 2850 |  ms/b 787.73 | train loss 0.00725868 | NA acc: 0.95 | not NA acc: 0.77  | tot acc: 0.89 \n| epoch  7 | step 2900 |  ms/b 780.03 | train loss 0.00746845 | NA acc: 0.94 | not NA acc: 0.77  | tot acc: 0.89 \n| epoch  7 | step 2950 |  ms/b 782.66 | train loss 0.00709623 | NA acc: 0.94 | not NA acc: 0.77  | tot acc: 0.89 \n| epoch  7 | step 3000 |  ms/b 786.37 | train loss 0.00749867 | NA acc: 0.94 | not NA acc: 0.77  | tot acc: 0.89 \n| epoch  7 | step 3050 |  ms/b 779.51 | train loss 0.00821385 | NA acc: 0.94 | not NA acc: 0.78  | tot acc: 0.89 \n| epoch  8 | step 3100 |  ms/b 782.00 | train loss 0.00703178 | NA acc: 0.95 | not NA acc: 0.80  | tot acc: 0.90 \n| epoch  8 | step 3150 |  ms/b 783.19 | train loss 0.00660176 | NA acc: 0.95 | not NA acc: 0.79  | tot acc: 0.89 \n| epoch  8 | step 3200 |  ms/b 787.49 | train loss 0.00639716 | NA acc: 0.95 | not NA acc: 0.80  | tot acc: 0.90 \n| epoch  8 | step 3250 |  ms/b 789.62 | train loss 0.00611941 | NA acc: 0.95 | not NA acc: 0.80  | tot acc: 0.90 \n| epoch  8 | step 3300 |  ms/b 790.46 | train loss 0.00655100 | NA acc: 0.95 | not NA acc: 0.80  | tot acc: 0.90 \n| epoch  8 | step 3350 |  ms/b 786.93 | train loss 0.00598257 | NA acc: 0.95 | not NA acc: 0.80  | tot acc: 0.90 \n| epoch  8 | step 3400 |  ms/b 783.93 | train loss 0.00661863 | NA acc: 0.95 | not NA acc: 0.80  | tot acc: 0.90 \n| epoch  9 | step 3450 |  ms/b 784.81 | train loss 0.00576232 | NA acc: 0.96 | not NA acc: 0.83  | tot acc: 0.91 \n| epoch  9 | step 3500 |  ms/b 786.86 | train loss 0.00565287 | NA acc: 0.95 | not NA acc: 0.82  | tot acc: 0.91 \n| epoch  9 | step 3550 |  ms/b 780.56 | train loss 0.00595206 | NA acc: 0.95 | not NA acc: 0.83  | tot acc: 0.91 \n| epoch  9 | step 3600 |  ms/b 783.47 | train loss 0.00565754 | NA acc: 0.95 | not NA acc: 0.83  | tot acc: 0.91 \n| epoch  9 | step 3650 |  ms/b 791.12 | train loss 0.00532614 | NA acc: 0.95 | not NA acc: 0.83  | tot acc: 0.91 \n| epoch  9 | step 3700 |  ms/b 786.63 | train loss 0.00600855 | NA acc: 0.95 | not NA acc: 0.83  | tot acc: 0.91 \n| epoch  9 | step 3750 |  ms/b 791.73 | train loss 0.00549817 | NA acc: 0.95 | not NA acc: 0.83  | tot acc: 0.91 \n| epoch  9 | step 3800 |  ms/b 785.26 | train loss 0.00526391 | NA acc: 0.95 | not NA acc: 0.83  | tot acc: 0.91 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.29\ntotal_recall 12323\npredicted as zero 362712\ntotal ins num 395726\ntop1_acc 8785\nALL  : Theta 0.9018 | F1 0.4934 | AUC 0.4681\nIgnore ma_f1 0.4679 | input_theta 0.9018 test_result F1 0.4672 | AUC 0.4325\n| epoch   9 | time: 194.64s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 10 | step 3850 |  ms/b 4671.45 | train loss 0.00564457 | NA acc: 0.95 | not NA acc: 0.85  | tot acc: 0.91 \n| epoch 10 | step 3900 |  ms/b 747.75 | train loss 0.00526647 | NA acc: 0.95 | not NA acc: 0.86  | tot acc: 0.92 \n| epoch 10 | step 3950 |  ms/b 760.68 | train loss 0.00522085 | NA acc: 0.95 | not NA acc: 0.85  | tot acc: 0.91 \n| epoch 10 | step 4000 |  ms/b 766.35 | train loss 0.00525448 | NA acc: 0.95 | not NA acc: 0.85  | tot acc: 0.91 \n| epoch 10 | step 4050 |  ms/b 768.76 | train loss 0.00509729 | NA acc: 0.95 | not NA acc: 0.86  | tot acc: 0.92 \n| epoch 10 | step 4100 |  ms/b 778.62 | train loss 0.00502097 | NA acc: 0.95 | not NA acc: 0.86  | tot acc: 0.92 \n| epoch 10 | step 4150 |  ms/b 779.82 | train loss 0.00510232 | NA acc: 0.95 | not NA acc: 0.86  | tot acc: 0.92 \n| epoch 10 | step 4200 |  ms/b 782.89 | train loss 0.00471951 | NA acc: 0.95 | not NA acc: 0.85  | tot acc: 0.92 \n| epoch 11 | step 4250 |  ms/b 782.29 | train loss 0.00479069 | NA acc: 0.95 | not NA acc: 0.87  | tot acc: 0.92 \n| epoch 11 | step 4300 |  ms/b 789.96 | train loss 0.00447347 | NA acc: 0.95 | not NA acc: 0.87  | tot acc: 0.93 \n| epoch 11 | step 4350 |  ms/b 789.68 | train loss 0.00438814 | NA acc: 0.95 | not NA acc: 0.87  | tot acc: 0.93 \n| epoch 11 | step 4400 |  ms/b 789.99 | train loss 0.00453682 | NA acc: 0.95 | not NA acc: 0.87  | tot acc: 0.93 \n| epoch 11 | step 4450 |  ms/b 789.79 | train loss 0.00436788 | NA acc: 0.96 | not NA acc: 0.87  | tot acc: 0.93 \n| epoch 11 | step 4500 |  ms/b 787.68 | train loss 0.00453928 | NA acc: 0.96 | not NA acc: 0.87  | tot acc: 0.93 \n| epoch 11 | step 4550 |  ms/b 788.93 | train loss 0.00511387 | NA acc: 0.95 | not NA acc: 0.87  | tot acc: 0.93 \n| epoch 12 | step 4600 |  ms/b 779.10 | train loss 0.00436833 | NA acc: 0.95 | not NA acc: 0.89  | tot acc: 0.93 \n| epoch 12 | step 4650 |  ms/b 791.47 | train loss 0.00432703 | NA acc: 0.96 | not NA acc: 0.88  | tot acc: 0.93 \n| epoch 12 | step 4700 |  ms/b 791.00 | train loss 0.00387754 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.93 \n| epoch 12 | step 4750 |  ms/b 784.11 | train loss 0.00417274 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.93 \n| epoch 12 | step 4800 |  ms/b 788.04 | train loss 0.00389637 | NA acc: 0.96 | not NA acc: 0.88  | tot acc: 0.93 \n| epoch 12 | step 4850 |  ms/b 786.43 | train loss 0.00398759 | NA acc: 0.96 | not NA acc: 0.88  | tot acc: 0.93 \n| epoch 12 | step 4900 |  ms/b 787.55 | train loss 0.00449311 | NA acc: 0.96 | not NA acc: 0.88  | tot acc: 0.93 \n| epoch 12 | step 4950 |  ms/b 786.65 | train loss 0.00457573 | NA acc: 0.96 | not NA acc: 0.88  | tot acc: 0.93 \n| epoch 13 | step 5000 |  ms/b 783.87 | train loss 0.00402201 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.93 \n| epoch 13 | step 5050 |  ms/b 793.92 | train loss 0.00388875 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.94 \n| epoch 13 | step 5100 |  ms/b 790.61 | train loss 0.00382416 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.94 \n| epoch 13 | step 5150 |  ms/b 782.81 | train loss 0.00381148 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.94 \n| epoch 13 | step 5200 |  ms/b 791.79 | train loss 0.00358382 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.94 \n| epoch 13 | step 5250 |  ms/b 790.60 | train loss 0.00391354 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.94 \n| epoch 13 | step 5300 |  ms/b 787.59 | train loss 0.00373481 | NA acc: 0.96 | not NA acc: 0.89  | tot acc: 0.94 \n| epoch 14 | step 5350 |  ms/b 784.28 | train loss 0.00408920 | NA acc: 0.98 | not NA acc: 0.92  | tot acc: 0.96 \n| epoch 14 | step 5400 |  ms/b 789.94 | train loss 0.00309385 | NA acc: 0.96 | not NA acc: 0.90  | tot acc: 0.94 \n| epoch 14 | step 5450 |  ms/b 787.65 | train loss 0.00342951 | NA acc: 0.96 | not NA acc: 0.90  | tot acc: 0.94 \n| epoch 14 | step 5500 |  ms/b 785.61 | train loss 0.00378663 | NA acc: 0.96 | not NA acc: 0.90  | tot acc: 0.94 \n| epoch 14 | step 5550 |  ms/b 786.26 | train loss 0.00330068 | NA acc: 0.96 | not NA acc: 0.90  | tot acc: 0.94 \n| epoch 14 | step 5600 |  ms/b 790.69 | train loss 0.00335691 | NA acc: 0.96 | not NA acc: 0.90  | tot acc: 0.94 \n| epoch 14 | step 5650 |  ms/b 785.14 | train loss 0.00373971 | NA acc: 0.96 | not NA acc: 0.90  | tot acc: 0.94 \n| epoch 14 | step 5700 |  ms/b 783.05 | train loss 0.00349298 | NA acc: 0.96 | not NA acc: 0.90  | tot acc: 0.94 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.30\ntotal_recall 12323\npredicted as zero 367528\ntotal ins num 395726\ntop1_acc 8561\nALL  : Theta 0.9471 | F1 0.4865 | AUC 0.4406\nIgnore ma_f1 0.4635 | input_theta 0.9471 test_result F1 0.4629 | AUC 0.4129\n| epoch  14 | time: 194.75s\n-----------------------------------------------------------------------------------------\n| epoch 15 | step 5750 |  ms/b 4657.48 | train loss 0.00392125 | NA acc: 0.97 | not NA acc: 0.90  | tot acc: 0.94 \n| epoch 15 | step 5800 |  ms/b 744.31 | train loss 0.00329845 | NA acc: 0.96 | not NA acc: 0.91  | tot acc: 0.95 \n| epoch 15 | step 5850 |  ms/b 757.87 | train loss 0.00324574 | NA acc: 0.96 | not NA acc: 0.91  | tot acc: 0.95 \n| epoch 15 | step 5900 |  ms/b 769.57 | train loss 0.00300695 | NA acc: 0.96 | not NA acc: 0.91  | tot acc: 0.95 \n| epoch 15 | step 5950 |  ms/b 769.86 | train loss 0.00330994 | NA acc: 0.96 | not NA acc: 0.91  | tot acc: 0.95 \n| epoch 15 | step 6000 |  ms/b 776.80 | train loss 0.00333731 | NA acc: 0.96 | not NA acc: 0.91  | tot acc: 0.95 \n| epoch 15 | step 6050 |  ms/b 786.96 | train loss 0.00344843 | NA acc: 0.96 | not NA acc: 0.91  | tot acc: 0.94 \n| epoch 15 | step 6100 |  ms/b 788.68 | train loss 0.00324949 | NA acc: 0.96 | not NA acc: 0.91  | tot acc: 0.95 \n| epoch 16 | step 6150 |  ms/b 787.91 | train loss 0.00286730 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.95 \n| epoch 16 | step 6200 |  ms/b 785.86 | train loss 0.00289969 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 16 | step 6250 |  ms/b 788.26 | train loss 0.00284697 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 16 | step 6300 |  ms/b 791.03 | train loss 0.00283484 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 16 | step 6350 |  ms/b 786.44 | train loss 0.00296338 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 16 | step 6400 |  ms/b 788.54 | train loss 0.00292870 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 16 | step 6450 |  ms/b 786.57 | train loss 0.00299957 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 17 | step 6500 |  ms/b 783.83 | train loss 0.00304043 | NA acc: 0.98 | not NA acc: 0.91  | tot acc: 0.96 \n| epoch 17 | step 6550 |  ms/b 785.80 | train loss 0.00271310 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 17 | step 6600 |  ms/b 793.93 | train loss 0.00253228 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 17 | step 6650 |  ms/b 787.01 | train loss 0.00273586 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 17 | step 6700 |  ms/b 789.14 | train loss 0.00274037 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 17 | step 6750 |  ms/b 791.17 | train loss 0.00286611 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 17 | step 6800 |  ms/b 790.04 | train loss 0.00287855 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 17 | step 6850 |  ms/b 784.24 | train loss 0.00294192 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 18 | step 6900 |  ms/b 789.15 | train loss 0.00282096 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 18 | step 6950 |  ms/b 791.71 | train loss 0.00290066 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 18 | step 7000 |  ms/b 788.43 | train loss 0.00244916 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 18 | step 7050 |  ms/b 791.23 | train loss 0.00277558 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 18 | step 7100 |  ms/b 781.58 | train loss 0.00246490 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 18 | step 7150 |  ms/b 783.01 | train loss 0.00284149 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 18 | step 7200 |  ms/b 786.50 | train loss 0.00294077 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 18 | step 7250 |  ms/b 781.39 | train loss 0.00285477 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 19 | step 7300 |  ms/b 783.88 | train loss 0.00275829 | NA acc: 0.97 | not NA acc: 0.92  | tot acc: 0.95 \n| epoch 19 | step 7350 |  ms/b 782.48 | train loss 0.00244884 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 19 | step 7400 |  ms/b 782.64 | train loss 0.00242420 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 19 | step 7450 |  ms/b 780.97 | train loss 0.00239601 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 19 | step 7500 |  ms/b 780.67 | train loss 0.00262469 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 19 | step 7550 |  ms/b 783.01 | train loss 0.00253598 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 19 | step 7600 |  ms/b 785.40 | train loss 0.00268270 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.25\ntotal_recall 12323\npredicted as zero 367994\ntotal ins num 395726\ntop1_acc 8624\nALL  : Theta 0.9661 | F1 0.5085 | AUC 0.4730\nIgnore ma_f1 0.4881 | input_theta 0.9661 test_result F1 0.4872 | AUC 0.4486\n| epoch  19 | time: 193.36s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 20 | step 7650 |  ms/b 4658.93 | train loss 0.00248859 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 20 | step 7700 |  ms/b 742.67 | train loss 0.00239715 | NA acc: 0.97 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 20 | step 7750 |  ms/b 757.52 | train loss 0.00251375 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 20 | step 7800 |  ms/b 765.19 | train loss 0.00244933 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 20 | step 7850 |  ms/b 772.37 | train loss 0.00223119 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 20 | step 7900 |  ms/b 773.98 | train loss 0.00257509 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 20 | step 7950 |  ms/b 783.70 | train loss 0.00250689 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 20 | step 8000 |  ms/b 783.96 | train loss 0.00253073 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 21 | step 8050 |  ms/b 786.07 | train loss 0.00224787 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 21 | step 8100 |  ms/b 784.28 | train loss 0.00220128 | NA acc: 0.97 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 21 | step 8150 |  ms/b 786.89 | train loss 0.00247402 | NA acc: 0.97 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 21 | step 8200 |  ms/b 793.75 | train loss 0.00222401 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 21 | step 8250 |  ms/b 790.95 | train loss 0.00245619 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 21 | step 8300 |  ms/b 785.02 | train loss 0.00203952 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 21 | step 8350 |  ms/b 790.48 | train loss 0.00225540 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 21 | step 8400 |  ms/b 790.05 | train loss 0.00222301 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 22 | step 8450 |  ms/b 783.36 | train loss 0.00213838 | NA acc: 0.97 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 22 | step 8500 |  ms/b 790.40 | train loss 0.00204656 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 22 | step 8550 |  ms/b 789.13 | train loss 0.00208778 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 22 | step 8600 |  ms/b 788.07 | train loss 0.00219423 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 22 | step 8650 |  ms/b 788.53 | train loss 0.00214910 | NA acc: 0.97 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 22 | step 8700 |  ms/b 790.47 | train loss 0.00229445 | NA acc: 0.97 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 22 | step 8750 |  ms/b 787.08 | train loss 0.00207692 | NA acc: 0.97 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 23 | step 8800 |  ms/b 783.94 | train loss 0.00186761 | NA acc: 0.97 | not NA acc: 0.95  | tot acc: 0.96 \n| epoch 23 | step 8850 |  ms/b 785.15 | train loss 0.00195122 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 23 | step 8900 |  ms/b 788.14 | train loss 0.00197261 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 23 | step 8950 |  ms/b 788.52 | train loss 0.00205128 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 23 | step 9000 |  ms/b 792.67 | train loss 0.00191544 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 23 | step 9050 |  ms/b 790.36 | train loss 0.00179720 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 23 | step 9100 |  ms/b 786.94 | train loss 0.00213446 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 23 | step 9150 |  ms/b 793.57 | train loss 0.00223132 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 24 | step 9200 |  ms/b 790.08 | train loss 0.00169483 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 24 | step 9250 |  ms/b 784.71 | train loss 0.00201937 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 24 | step 9300 |  ms/b 787.96 | train loss 0.00179689 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 24 | step 9350 |  ms/b 782.91 | train loss 0.00175418 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 24 | step 9400 |  ms/b 788.62 | train loss 0.00176807 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 24 | step 9450 |  ms/b 792.67 | train loss 0.00174766 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 24 | step 9500 |  ms/b 789.39 | train loss 0.00179513 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 24 | step 9550 |  ms/b 774.08 | train loss 0.00176728 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 77.87\ntotal_recall 12323\npredicted as zero 355129\ntotal ins num 395726\ntop1_acc 9416\nALL  : Theta 0.9947 | F1 0.5251 | AUC 0.4953\nIgnore ma_f1 0.5019 | input_theta 0.9947 test_result F1 0.4996 | AUC 0.4613\n| epoch  24 | time: 193.29s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 25 | step 9600 |  ms/b 4635.78 | train loss 0.00198491 | NA acc: 0.97 | not NA acc: 0.93  | tot acc: 0.96 \n| epoch 25 | step 9650 |  ms/b 749.06 | train loss 0.00161740 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 25 | step 9700 |  ms/b 762.29 | train loss 0.00184505 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.96 \n| epoch 25 | step 9750 |  ms/b 770.12 | train loss 0.00166812 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 25 | step 9800 |  ms/b 776.65 | train loss 0.00171056 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 25 | step 9850 |  ms/b 777.16 | train loss 0.00173273 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 25 | step 9900 |  ms/b 783.01 | train loss 0.00182227 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 26 | step 9950 |  ms/b 787.46 | train loss 0.00162098 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 26 | step 10000 |  ms/b 792.50 | train loss 0.00177843 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 26 | step 10050 |  ms/b 791.67 | train loss 0.00149242 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 26 | step 10100 |  ms/b 781.60 | train loss 0.00155813 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 26 | step 10150 |  ms/b 783.36 | train loss 0.00156095 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 26 | step 10200 |  ms/b 779.58 | train loss 0.00152269 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 26 | step 10250 |  ms/b 790.41 | train loss 0.00167331 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 26 | step 10300 |  ms/b 783.55 | train loss 0.00163409 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 27 | step 10350 |  ms/b 783.50 | train loss 0.00163389 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 27 | step 10400 |  ms/b 789.72 | train loss 0.00150076 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 27 | step 10450 |  ms/b 785.77 | train loss 0.00148402 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 27 | step 10500 |  ms/b 786.35 | train loss 0.00140080 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 27 | step 10550 |  ms/b 787.51 | train loss 0.00144751 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 27 | step 10600 |  ms/b 790.13 | train loss 0.00147321 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 27 | step 10650 |  ms/b 788.31 | train loss 0.00146702 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 28 | step 10700 |  ms/b 783.92 | train loss 0.00164198 | NA acc: 0.98 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 28 | step 10750 |  ms/b 788.48 | train loss 0.00144642 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 28 | step 10800 |  ms/b 791.63 | train loss 0.00150863 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 28 | step 10850 |  ms/b 784.61 | train loss 0.00145707 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 28 | step 10900 |  ms/b 790.11 | train loss 0.00132894 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 28 | step 10950 |  ms/b 794.16 | train loss 0.00156927 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 28 | step 11000 |  ms/b 792.00 | train loss 0.00152114 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 28 | step 11050 |  ms/b 790.09 | train loss 0.00149612 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 29 | step 11100 |  ms/b 787.24 | train loss 0.00151558 | NA acc: 0.99 | not NA acc: 0.94  | tot acc: 0.97 \n| epoch 29 | step 11150 |  ms/b 785.45 | train loss 0.00137193 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 29 | step 11200 |  ms/b 785.01 | train loss 0.00145798 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 29 | step 11250 |  ms/b 782.04 | train loss 0.00132794 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 29 | step 11300 |  ms/b 778.39 | train loss 0.00129332 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 29 | step 11350 |  ms/b 783.29 | train loss 0.00150789 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 29 | step 11400 |  ms/b 784.82 | train loss 0.00146883 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 29 | step 11450 |  ms/b 784.79 | train loss 0.00133949 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.09\ntotal_recall 12323\npredicted as zero 377168\ntotal ins num 395726\ntop1_acc 7860\nALL  : Theta 0.9205 | F1 0.5332 | AUC 0.5120\nIgnore ma_f1 0.5097 | input_theta 0.9205 test_result F1 0.5095 | AUC 0.4773\n| epoch  29 | time: 194.18s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 30 | step 11500 |  ms/b 4650.12 | train loss 0.00135812 | NA acc: 0.98 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 30 | step 11550 |  ms/b 750.66 | train loss 0.00132116 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 30 | step 11600 |  ms/b 760.49 | train loss 0.00124885 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 30 | step 11650 |  ms/b 768.76 | train loss 0.00120816 | NA acc: 0.98 | not NA acc: 0.96  | tot acc: 0.97 \n| epoch 30 | step 11700 |  ms/b 776.44 | train loss 0.00137219 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 30 | step 11750 |  ms/b 783.43 | train loss 0.00124625 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 30 | step 11800 |  ms/b 782.67 | train loss 0.00138891 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 31 | step 11850 |  ms/b 782.46 | train loss 0.00127681 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 31 | step 11900 |  ms/b 785.24 | train loss 0.00106075 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 31 | step 11950 |  ms/b 796.01 | train loss 0.00147279 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 31 | step 12000 |  ms/b 787.56 | train loss 0.00121731 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 31 | step 12050 |  ms/b 783.90 | train loss 0.00113321 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 31 | step 12100 |  ms/b 788.90 | train loss 0.00142535 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 31 | step 12150 |  ms/b 790.17 | train loss 0.00136337 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 31 | step 12200 |  ms/b 789.79 | train loss 0.00111412 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 32 | step 12250 |  ms/b 782.22 | train loss 0.00123590 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 32 | step 12300 |  ms/b 784.51 | train loss 0.00111679 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 32 | step 12350 |  ms/b 784.50 | train loss 0.00118260 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 32 | step 12400 |  ms/b 795.58 | train loss 0.00108914 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 32 | step 12450 |  ms/b 786.57 | train loss 0.00134123 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 32 | step 12500 |  ms/b 783.37 | train loss 0.00114725 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 32 | step 12550 |  ms/b 792.42 | train loss 0.00150115 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 32 | step 12600 |  ms/b 791.74 | train loss 0.00112054 | NA acc: 0.98 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 33 | step 12650 |  ms/b 784.25 | train loss 0.00111694 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 33 | step 12700 |  ms/b 782.86 | train loss 0.00099715 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 33 | step 12750 |  ms/b 788.12 | train loss 0.00119539 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 33 | step 12800 |  ms/b 789.83 | train loss 0.00121121 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 33 | step 12850 |  ms/b 787.48 | train loss 0.00112637 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 33 | step 12900 |  ms/b 785.56 | train loss 0.00129860 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 33 | step 12950 |  ms/b 784.81 | train loss 0.00116170 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 34 | step 13000 |  ms/b 785.75 | train loss 0.00118928 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 34 | step 13050 |  ms/b 784.85 | train loss 0.00095317 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 34 | step 13100 |  ms/b 788.42 | train loss 0.00108209 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 34 | step 13150 |  ms/b 791.21 | train loss 0.00112027 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 34 | step 13200 |  ms/b 791.02 | train loss 0.00120130 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 34 | step 13250 |  ms/b 786.39 | train loss 0.00102902 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 34 | step 13300 |  ms/b 785.90 | train loss 0.00105432 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 34 | step 13350 |  ms/b 786.11 | train loss 0.00104839 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.32\ntotal_recall 12323\npredicted as zero 376818\ntotal ins num 395726\ntop1_acc 7910\nALL  : Theta 0.9418 | F1 0.5333 | AUC 0.4958\nIgnore ma_f1 0.5102 | input_theta 0.9418 test_result F1 0.5101 | AUC 0.4598\n| epoch  34 | time: 194.09s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 35 | step 13400 |  ms/b 4660.13 | train loss 0.00112202 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 35 | step 13450 |  ms/b 748.86 | train loss 0.00093443 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 35 | step 13500 |  ms/b 757.04 | train loss 0.00108819 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 35 | step 13550 |  ms/b 767.39 | train loss 0.00099295 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 35 | step 13600 |  ms/b 776.95 | train loss 0.00105565 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 35 | step 13650 |  ms/b 773.99 | train loss 0.00104543 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 35 | step 13700 |  ms/b 778.40 | train loss 0.00103274 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 35 | step 13750 |  ms/b 784.13 | train loss 0.00125197 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 36 | step 13800 |  ms/b 784.87 | train loss 0.00113323 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 36 | step 13850 |  ms/b 783.34 | train loss 0.00094959 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 36 | step 13900 |  ms/b 789.57 | train loss 0.00105562 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 36 | step 13950 |  ms/b 789.75 | train loss 0.00120188 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 36 | step 14000 |  ms/b 785.08 | train loss 0.00100392 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 36 | step 14050 |  ms/b 788.53 | train loss 0.00106698 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 36 | step 14100 |  ms/b 781.19 | train loss 0.00095951 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 37 | step 14150 |  ms/b 785.88 | train loss 0.00096998 | NA acc: 0.99 | not NA acc: 0.97  | tot acc: 0.98 \n| epoch 37 | step 14200 |  ms/b 789.06 | train loss 0.00101401 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 37 | step 14250 |  ms/b 789.74 | train loss 0.00106079 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 37 | step 14300 |  ms/b 786.75 | train loss 0.00098877 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 37 | step 14350 |  ms/b 784.77 | train loss 0.00101534 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 37 | step 14400 |  ms/b 783.49 | train loss 0.00088836 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 37 | step 14450 |  ms/b 793.11 | train loss 0.00102208 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 37 | step 14500 |  ms/b 786.20 | train loss 0.00098860 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 38 | step 14550 |  ms/b 783.56 | train loss 0.00097662 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.97 \n| epoch 38 | step 14600 |  ms/b 785.49 | train loss 0.00088714 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 38 | step 14650 |  ms/b 790.56 | train loss 0.00093550 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 38 | step 14700 |  ms/b 782.10 | train loss 0.00090206 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 38 | step 14750 |  ms/b 787.46 | train loss 0.00089593 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 38 | step 14800 |  ms/b 782.09 | train loss 0.00103777 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 38 | step 14850 |  ms/b 790.26 | train loss 0.00084084 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 39 | step 14900 |  ms/b 787.14 | train loss 0.00088698 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 39 | step 14950 |  ms/b 784.95 | train loss 0.00093608 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 39 | step 15000 |  ms/b 789.45 | train loss 0.00094593 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 39 | step 15050 |  ms/b 790.27 | train loss 0.00080379 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 39 | step 15100 |  ms/b 784.16 | train loss 0.00073821 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 39 | step 15150 |  ms/b 784.20 | train loss 0.00085762 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 39 | step 15200 |  ms/b 794.06 | train loss 0.00092725 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 39 | step 15250 |  ms/b 784.70 | train loss 0.00094430 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.25\ntotal_recall 12323\npredicted as zero 379525\ntotal ins num 395726\ntop1_acc 7502\nALL  : Theta 0.9140 | F1 0.5394 | AUC 0.5139\nIgnore ma_f1 0.5170 | input_theta 0.9140 test_result F1 0.5166 | AUC 0.4814\n| epoch  39 | time: 193.34s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 40 | step 15300 |  ms/b 4647.14 | train loss 0.00085219 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 40 | step 15350 |  ms/b 737.05 | train loss 0.00087654 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 40 | step 15400 |  ms/b 760.53 | train loss 0.00081877 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 40 | step 15450 |  ms/b 760.11 | train loss 0.00093241 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 40 | step 15500 |  ms/b 773.63 | train loss 0.00102355 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 40 | step 15550 |  ms/b 773.64 | train loss 0.00099147 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 40 | step 15600 |  ms/b 781.19 | train loss 0.00078063 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 40 | step 15650 |  ms/b 787.00 | train loss 0.00096126 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 41 | step 15700 |  ms/b 777.63 | train loss 0.00095310 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 41 | step 15750 |  ms/b 782.75 | train loss 0.00092569 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 41 | step 15800 |  ms/b 783.57 | train loss 0.00094027 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 41 | step 15850 |  ms/b 785.72 | train loss 0.00095860 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 41 | step 15900 |  ms/b 791.10 | train loss 0.00083755 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 41 | step 15950 |  ms/b 788.26 | train loss 0.00095240 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 41 | step 16000 |  ms/b 785.43 | train loss 0.00083873 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 42 | step 16050 |  ms/b 784.11 | train loss 0.00078618 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 42 | step 16100 |  ms/b 781.27 | train loss 0.00089564 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 42 | step 16150 |  ms/b 785.97 | train loss 0.00081075 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 42 | step 16200 |  ms/b 784.42 | train loss 0.00077492 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 42 | step 16250 |  ms/b 783.02 | train loss 0.00081662 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 42 | step 16300 |  ms/b 784.94 | train loss 0.00078452 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 42 | step 16350 |  ms/b 783.44 | train loss 0.00084287 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 42 | step 16400 |  ms/b 789.65 | train loss 0.00078684 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 43 | step 16450 |  ms/b 780.46 | train loss 0.00066423 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 43 | step 16500 |  ms/b 786.92 | train loss 0.00082386 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 43 | step 16550 |  ms/b 789.68 | train loss 0.00077089 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 43 | step 16600 |  ms/b 785.95 | train loss 0.00084060 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 43 | step 16650 |  ms/b 783.47 | train loss 0.00070958 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 43 | step 16700 |  ms/b 777.20 | train loss 0.00075547 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 43 | step 16750 |  ms/b 786.64 | train loss 0.00070662 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 43 | step 16800 |  ms/b 782.47 | train loss 0.00081944 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 44 | step 16850 |  ms/b 776.26 | train loss 0.00099759 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 44 | step 16900 |  ms/b 781.11 | train loss 0.00066712 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 44 | step 16950 |  ms/b 782.99 | train loss 0.00069490 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 44 | step 17000 |  ms/b 778.29 | train loss 0.00066657 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 44 | step 17050 |  ms/b 783.80 | train loss 0.00082221 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 44 | step 17100 |  ms/b 781.95 | train loss 0.00074117 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 44 | step 17150 |  ms/b 783.40 | train loss 0.00085169 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.25\ntotal_recall 12323\npredicted as zero 377374\ntotal ins num 395726\ntop1_acc 7898\nALL  : Theta 0.9561 | F1 0.5428 | AUC 0.5230\nIgnore ma_f1 0.5225 | input_theta 0.9561 test_result F1 0.5222 | AUC 0.4944\n| epoch  44 | time: 193.13s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 45 | step 17200 |  ms/b 4661.11 | train loss 0.00066253 | NA acc: 0.99 | not NA acc: 0.97  | tot acc: 0.98 \n| epoch 45 | step 17250 |  ms/b 734.38 | train loss 0.00068484 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 45 | step 17300 |  ms/b 755.82 | train loss 0.00069247 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 45 | step 17350 |  ms/b 762.00 | train loss 0.00077632 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 45 | step 17400 |  ms/b 774.18 | train loss 0.00069740 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 45 | step 17450 |  ms/b 780.86 | train loss 0.00071567 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 45 | step 17500 |  ms/b 777.60 | train loss 0.00072778 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 45 | step 17550 |  ms/b 788.43 | train loss 0.00075741 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 46 | step 17600 |  ms/b 782.14 | train loss 0.00061479 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 46 | step 17650 |  ms/b 783.06 | train loss 0.00057032 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 46 | step 17700 |  ms/b 785.37 | train loss 0.00054930 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 46 | step 17750 |  ms/b 789.23 | train loss 0.00056448 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 46 | step 17800 |  ms/b 780.89 | train loss 0.00059730 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 46 | step 17850 |  ms/b 783.07 | train loss 0.00071468 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 46 | step 17900 |  ms/b 784.34 | train loss 0.00072617 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 46 | step 17950 |  ms/b 788.61 | train loss 0.00068607 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 47 | step 18000 |  ms/b 781.95 | train loss 0.00078565 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 47 | step 18050 |  ms/b 780.06 | train loss 0.00062289 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 47 | step 18100 |  ms/b 785.84 | train loss 0.00058924 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 47 | step 18150 |  ms/b 786.08 | train loss 0.00065415 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 47 | step 18200 |  ms/b 789.13 | train loss 0.00078163 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 47 | step 18250 |  ms/b 784.15 | train loss 0.00055495 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 47 | step 18300 |  ms/b 786.36 | train loss 0.00072911 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 48 | step 18350 |  ms/b 786.42 | train loss 0.00066971 | NA acc: 0.99 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 48 | step 18400 |  ms/b 781.57 | train loss 0.00072349 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 48 | step 18450 |  ms/b 781.23 | train loss 0.00068237 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 48 | step 18500 |  ms/b 787.63 | train loss 0.00061432 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 48 | step 18550 |  ms/b 789.27 | train loss 0.00065912 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 48 | step 18600 |  ms/b 789.62 | train loss 0.00059094 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 48 | step 18650 |  ms/b 787.24 | train loss 0.00064505 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 48 | step 18700 |  ms/b 784.58 | train loss 0.00065733 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 49 | step 18750 |  ms/b 788.40 | train loss 0.00071328 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 49 | step 18800 |  ms/b 782.13 | train loss 0.00057936 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 49 | step 18850 |  ms/b 783.71 | train loss 0.00060243 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 49 | step 18900 |  ms/b 780.20 | train loss 0.00074421 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 49 | step 18950 |  ms/b 781.20 | train loss 0.00061241 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 49 | step 19000 |  ms/b 786.77 | train loss 0.00051148 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 49 | step 19050 |  ms/b 786.23 | train loss 0.00053075 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 49 | step 19100 |  ms/b 778.71 | train loss 0.00070314 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.21\ntotal_recall 12323\npredicted as zero 377872\ntotal ins num 395726\ntop1_acc 7766\nALL  : Theta 0.9435 | F1 0.5479 | AUC 0.5204\nIgnore ma_f1 0.5258 | input_theta 0.9435 test_result F1 0.5248 | AUC 0.4841\n| epoch  49 | time: 193.27s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 50 | step 19150 |  ms/b 4628.75 | train loss 0.00063435 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 50 | step 19200 |  ms/b 752.05 | train loss 0.00062333 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 50 | step 19250 |  ms/b 764.73 | train loss 0.00056460 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 50 | step 19300 |  ms/b 769.64 | train loss 0.00070384 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 50 | step 19350 |  ms/b 777.30 | train loss 0.00067635 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 50 | step 19400 |  ms/b 780.50 | train loss 0.00064418 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 50 | step 19450 |  ms/b 782.59 | train loss 0.00065860 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 51 | step 19500 |  ms/b 778.29 | train loss 0.00056978 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 51 | step 19550 |  ms/b 782.65 | train loss 0.00063950 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 51 | step 19600 |  ms/b 786.85 | train loss 0.00064593 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 51 | step 19650 |  ms/b 787.62 | train loss 0.00056655 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 51 | step 19700 |  ms/b 781.41 | train loss 0.00062214 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 51 | step 19750 |  ms/b 784.07 | train loss 0.00048747 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 51 | step 19800 |  ms/b 786.05 | train loss 0.00072454 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 51 | step 19850 |  ms/b 786.65 | train loss 0.00057730 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 52 | step 19900 |  ms/b 783.51 | train loss 0.00055119 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 52 | step 19950 |  ms/b 786.42 | train loss 0.00057050 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 52 | step 20000 |  ms/b 783.72 | train loss 0.00053707 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 52 | step 20050 |  ms/b 789.92 | train loss 0.00073992 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 52 | step 20100 |  ms/b 785.70 | train loss 0.00073338 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 52 | step 20150 |  ms/b 785.62 | train loss 0.00066196 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 52 | step 20200 |  ms/b 787.14 | train loss 0.00052693 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 53 | step 20250 |  ms/b 785.67 | train loss 0.00060671 | NA acc: 0.99 | not NA acc: 0.94  | tot acc: 0.98 \n| epoch 53 | step 20300 |  ms/b 781.18 | train loss 0.00053049 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 53 | step 20350 |  ms/b 783.84 | train loss 0.00061984 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 53 | step 20400 |  ms/b 784.41 | train loss 0.00058385 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 53 | step 20450 |  ms/b 785.58 | train loss 0.00069637 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 53 | step 20500 |  ms/b 786.82 | train loss 0.00059283 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 53 | step 20550 |  ms/b 782.04 | train loss 0.00061057 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 53 | step 20600 |  ms/b 786.33 | train loss 0.00055056 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 54 | step 20650 |  ms/b 781.31 | train loss 0.00061465 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 54 | step 20700 |  ms/b 782.25 | train loss 0.00068138 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 54 | step 20750 |  ms/b 788.85 | train loss 0.00061833 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 54 | step 20800 |  ms/b 785.39 | train loss 0.00048268 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 54 | step 20850 |  ms/b 788.54 | train loss 0.00050307 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 54 | step 20900 |  ms/b 780.38 | train loss 0.00051203 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 54 | step 20950 |  ms/b 777.48 | train loss 0.00061004 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 54 | step 21000 |  ms/b 788.83 | train loss 0.00044121 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 77.76\ntotal_recall 12323\npredicted as zero 380348\ntotal ins num 395726\ntop1_acc 7427\nALL  : Theta 0.8451 | F1 0.5547 | AUC 0.5362\nIgnore ma_f1 0.5328 | input_theta 0.8451 test_result F1 0.5313 | AUC 0.5062\n| epoch  54 | time: 192.97s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 55 | step 21050 |  ms/b 4633.14 | train loss 0.00051624 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 55 | step 21100 |  ms/b 751.18 | train loss 0.00055540 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 55 | step 21150 |  ms/b 757.30 | train loss 0.00042575 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 55 | step 21200 |  ms/b 768.95 | train loss 0.00059689 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 55 | step 21250 |  ms/b 773.99 | train loss 0.00045953 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 55 | step 21300 |  ms/b 778.71 | train loss 0.00044363 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 55 | step 21350 |  ms/b 778.48 | train loss 0.00047520 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 56 | step 21400 |  ms/b 778.77 | train loss 0.00051232 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 56 | step 21450 |  ms/b 785.71 | train loss 0.00069026 | NA acc: 0.99 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 56 | step 21500 |  ms/b 782.66 | train loss 0.00040482 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 56 | step 21550 |  ms/b 784.01 | train loss 0.00049032 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 56 | step 21600 |  ms/b 790.35 | train loss 0.00050659 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 56 | step 21650 |  ms/b 782.53 | train loss 0.00038079 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 56 | step 21700 |  ms/b 784.62 | train loss 0.00048525 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 56 | step 21750 |  ms/b 788.13 | train loss 0.00044372 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 57 | step 21800 |  ms/b 786.40 | train loss 0.00051407 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 57 | step 21850 |  ms/b 785.88 | train loss 0.00046598 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 57 | step 21900 |  ms/b 779.86 | train loss 0.00045185 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 57 | step 21950 |  ms/b 783.31 | train loss 0.00043664 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 57 | step 22000 |  ms/b 790.95 | train loss 0.00054874 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 57 | step 22050 |  ms/b 781.89 | train loss 0.00048424 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 57 | step 22100 |  ms/b 783.14 | train loss 0.00046290 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 57 | step 22150 |  ms/b 785.81 | train loss 0.00043736 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 58 | step 22200 |  ms/b 780.63 | train loss 0.00047048 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 58 | step 22250 |  ms/b 790.57 | train loss 0.00042659 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 58 | step 22300 |  ms/b 784.81 | train loss 0.00047094 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 58 | step 22350 |  ms/b 789.45 | train loss 0.00045555 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 58 | step 22400 |  ms/b 783.75 | train loss 0.00049661 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 58 | step 22450 |  ms/b 782.07 | train loss 0.00046933 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 58 | step 22500 |  ms/b 785.92 | train loss 0.00039380 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 59 | step 22550 |  ms/b 782.95 | train loss 0.00042467 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 59 | step 22600 |  ms/b 788.94 | train loss 0.00042900 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 59 | step 22650 |  ms/b 787.72 | train loss 0.00041807 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 59 | step 22700 |  ms/b 788.33 | train loss 0.00050417 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 59 | step 22750 |  ms/b 783.95 | train loss 0.00048785 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 59 | step 22800 |  ms/b 791.50 | train loss 0.00041622 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 59 | step 22850 |  ms/b 787.33 | train loss 0.00049022 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 59 | step 22900 |  ms/b 783.87 | train loss 0.00045890 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.49\ntotal_recall 12323\npredicted as zero 378448\ntotal ins num 395726\ntop1_acc 7776\nALL  : Theta 0.9297 | F1 0.5539 | AUC 0.5298\nIgnore ma_f1 0.5304 | input_theta 0.9297 test_result F1 0.5303 | AUC 0.4971\n| epoch  59 | time: 194.52s\n-----------------------------------------------------------------------------------------\n| epoch 60 | step 22950 |  ms/b 4645.94 | train loss 0.00047178 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 60 | step 23000 |  ms/b 747.66 | train loss 0.00042776 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 60 | step 23050 |  ms/b 755.16 | train loss 0.00046144 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 60 | step 23100 |  ms/b 766.70 | train loss 0.00046731 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 60 | step 23150 |  ms/b 775.32 | train loss 0.00065234 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 60 | step 23200 |  ms/b 776.46 | train loss 0.00035162 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 60 | step 23250 |  ms/b 779.51 | train loss 0.00042947 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 60 | step 23300 |  ms/b 781.81 | train loss 0.00041189 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 61 | step 23350 |  ms/b 783.03 | train loss 0.00038699 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 61 | step 23400 |  ms/b 779.08 | train loss 0.00033911 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 61 | step 23450 |  ms/b 789.42 | train loss 0.00047742 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 61 | step 23500 |  ms/b 788.61 | train loss 0.00053947 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 61 | step 23550 |  ms/b 784.55 | train loss 0.00037382 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 61 | step 23600 |  ms/b 779.70 | train loss 0.00042541 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 61 | step 23650 |  ms/b 787.89 | train loss 0.00047352 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 62 | step 23700 |  ms/b 781.98 | train loss 0.00038650 | NA acc: 0.99 | not NA acc: 0.97  | tot acc: 0.98 \n| epoch 62 | step 23750 |  ms/b 786.99 | train loss 0.00035794 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 62 | step 23800 |  ms/b 785.39 | train loss 0.00036412 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 62 | step 23850 |  ms/b 790.41 | train loss 0.00036343 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 62 | step 23900 |  ms/b 785.27 | train loss 0.00034847 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 62 | step 23950 |  ms/b 787.74 | train loss 0.00038463 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 62 | step 24000 |  ms/b 785.48 | train loss 0.00048172 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 62 | step 24050 |  ms/b 786.95 | train loss 0.00060297 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 63 | step 24100 |  ms/b 782.98 | train loss 0.00030363 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 63 | step 24150 |  ms/b 788.83 | train loss 0.00035986 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 63 | step 24200 |  ms/b 784.18 | train loss 0.00031497 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 63 | step 24250 |  ms/b 781.23 | train loss 0.00047062 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 63 | step 24300 |  ms/b 789.91 | train loss 0.00038902 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 63 | step 24350 |  ms/b 779.89 | train loss 0.00043547 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 63 | step 24400 |  ms/b 780.94 | train loss 0.00046411 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 64 | step 24450 |  ms/b 783.82 | train loss 0.00053221 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 64 | step 24500 |  ms/b 783.54 | train loss 0.00048330 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 64 | step 24550 |  ms/b 786.16 | train loss 0.00054746 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 64 | step 24600 |  ms/b 798.14 | train loss 0.00071659 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 64 | step 24650 |  ms/b 785.34 | train loss 0.00042071 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 64 | step 24700 |  ms/b 788.89 | train loss 0.00042004 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 64 | step 24750 |  ms/b 784.28 | train loss 0.00035279 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 64 | step 24800 |  ms/b 789.17 | train loss 0.00043215 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.11\ntotal_recall 12323\npredicted as zero 381390\ntotal ins num 395726\ntop1_acc 7231\nALL  : Theta 0.8711 | F1 0.5559 | AUC 0.5307\nIgnore ma_f1 0.5345 | input_theta 0.8711 test_result F1 0.5328 | AUC 0.4976\n| epoch  64 | time: 192.98s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 65 | step 24850 |  ms/b 4646.42 | train loss 0.00038660 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 65 | step 24900 |  ms/b 744.88 | train loss 0.00035050 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 65 | step 24950 |  ms/b 754.41 | train loss 0.00039940 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 65 | step 25000 |  ms/b 764.85 | train loss 0.00045651 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 65 | step 25050 |  ms/b 772.60 | train loss 0.00051084 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 65 | step 25100 |  ms/b 776.68 | train loss 0.00037411 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 65 | step 25150 |  ms/b 780.09 | train loss 0.00040599 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 65 | step 25200 |  ms/b 772.82 | train loss 0.00040095 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 66 | step 25250 |  ms/b 780.28 | train loss 0.00038806 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 66 | step 25300 |  ms/b 788.62 | train loss 0.00041566 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 66 | step 25350 |  ms/b 783.25 | train loss 0.00035856 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 66 | step 25400 |  ms/b 782.80 | train loss 0.00043327 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 66 | step 25450 |  ms/b 787.20 | train loss 0.00033519 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 66 | step 25500 |  ms/b 789.98 | train loss 0.00029648 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 66 | step 25550 |  ms/b 787.08 | train loss 0.00034990 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 67 | step 25600 |  ms/b 783.35 | train loss 0.00039768 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 67 | step 25650 |  ms/b 780.15 | train loss 0.00037124 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 67 | step 25700 |  ms/b 791.40 | train loss 0.00037427 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 67 | step 25750 |  ms/b 789.93 | train loss 0.00038123 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 67 | step 25800 |  ms/b 786.59 | train loss 0.00033075 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 67 | step 25850 |  ms/b 789.31 | train loss 0.00033326 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 67 | step 25900 |  ms/b 792.52 | train loss 0.00038283 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 67 | step 25950 |  ms/b 782.10 | train loss 0.00032941 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 68 | step 26000 |  ms/b 782.09 | train loss 0.00035465 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 68 | step 26050 |  ms/b 783.95 | train loss 0.00055354 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 68 | step 26100 |  ms/b 783.76 | train loss 0.00040310 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 68 | step 26150 |  ms/b 780.35 | train loss 0.00036453 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 68 | step 26200 |  ms/b 785.82 | train loss 0.00038101 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 68 | step 26250 |  ms/b 781.90 | train loss 0.00032204 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 68 | step 26300 |  ms/b 786.30 | train loss 0.00034737 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 68 | step 26350 |  ms/b 781.61 | train loss 0.00032265 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 69 | step 26400 |  ms/b 781.00 | train loss 0.00039932 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 69 | step 26450 |  ms/b 783.91 | train loss 0.00033677 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 69 | step 26500 |  ms/b 781.00 | train loss 0.00039161 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 69 | step 26550 |  ms/b 782.06 | train loss 0.00037154 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 69 | step 26600 |  ms/b 781.24 | train loss 0.00045573 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 69 | step 26650 |  ms/b 782.10 | train loss 0.00040889 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 69 | step 26700 |  ms/b 781.52 | train loss 0.00045739 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.33\ntotal_recall 12323\npredicted as zero 380692\ntotal ins num 395726\ntop1_acc 7267\nALL  : Theta 0.8570 | F1 0.5459 | AUC 0.5089\nIgnore ma_f1 0.5225 | input_theta 0.8570 test_result F1 0.5223 | AUC 0.4758\n| epoch  69 | time: 193.42s\n-----------------------------------------------------------------------------------------\n| epoch 70 | step 26750 |  ms/b 4641.47 | train loss 0.00039838 | NA acc: 1.00 | not NA acc: 0.98  | tot acc: 0.99 \n| epoch 70 | step 26800 |  ms/b 739.10 | train loss 0.00043090 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 70 | step 26850 |  ms/b 751.39 | train loss 0.00037258 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 70 | step 26900 |  ms/b 766.43 | train loss 0.00039565 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 70 | step 26950 |  ms/b 769.31 | train loss 0.00036111 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 70 | step 27000 |  ms/b 772.77 | train loss 0.00038452 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 70 | step 27050 |  ms/b 778.52 | train loss 0.00028069 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 70 | step 27100 |  ms/b 783.56 | train loss 0.00032545 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 71 | step 27150 |  ms/b 773.68 | train loss 0.00028023 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 71 | step 27200 |  ms/b 782.76 | train loss 0.00037432 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 71 | step 27250 |  ms/b 781.91 | train loss 0.00032309 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 71 | step 27300 |  ms/b 785.99 | train loss 0.00030374 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 71 | step 27350 |  ms/b 788.02 | train loss 0.00030971 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 71 | step 27400 |  ms/b 781.81 | train loss 0.00028623 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 71 | step 27450 |  ms/b 789.80 | train loss 0.00037633 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 71 | step 27500 |  ms/b 786.26 | train loss 0.00047921 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 72 | step 27550 |  ms/b 782.43 | train loss 0.00027031 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 72 | step 27600 |  ms/b 785.57 | train loss 0.00036363 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 72 | step 27650 |  ms/b 786.86 | train loss 0.00035085 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 72 | step 27700 |  ms/b 784.69 | train loss 0.00029604 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 72 | step 27750 |  ms/b 785.66 | train loss 0.00034865 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 72 | step 27800 |  ms/b 783.39 | train loss 0.00042812 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 72 | step 27850 |  ms/b 788.02 | train loss 0.00025574 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 73 | step 27900 |  ms/b 788.84 | train loss 0.00028898 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 73 | step 27950 |  ms/b 790.92 | train loss 0.00034545 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 73 | step 28000 |  ms/b 787.21 | train loss 0.00031355 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 73 | step 28050 |  ms/b 782.75 | train loss 0.00025435 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 73 | step 28100 |  ms/b 783.41 | train loss 0.00032057 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 73 | step 28150 |  ms/b 785.87 | train loss 0.00029213 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 73 | step 28200 |  ms/b 786.56 | train loss 0.00031675 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 73 | step 28250 |  ms/b 784.70 | train loss 0.00053928 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 74 | step 28300 |  ms/b 780.41 | train loss 0.00032219 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 74 | step 28350 |  ms/b 786.01 | train loss 0.00026508 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 74 | step 28400 |  ms/b 785.86 | train loss 0.00028182 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 74 | step 28450 |  ms/b 784.36 | train loss 0.00027699 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 74 | step 28500 |  ms/b 783.67 | train loss 0.00029465 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 74 | step 28550 |  ms/b 783.23 | train loss 0.00021952 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 74 | step 28600 |  ms/b 785.26 | train loss 0.00028630 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 74 | step 28650 |  ms/b 789.09 | train loss 0.00031350 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.80\ntotal_recall 12323\npredicted as zero 380275\ntotal ins num 395726\ntop1_acc 7439\nALL  : Theta 0.9274 | F1 0.5530 | AUC 0.5254\nIgnore ma_f1 0.5307 | input_theta 0.9274 test_result F1 0.5299 | AUC 0.4915\n| epoch  74 | time: 193.37s\n-----------------------------------------------------------------------------------------\n| epoch 75 | step 28700 |  ms/b 4610.83 | train loss 0.00041838 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 75 | step 28750 |  ms/b 746.14 | train loss 0.00026209 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 75 | step 28800 |  ms/b 761.68 | train loss 0.00020408 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 75 | step 28850 |  ms/b 763.60 | train loss 0.00022782 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 75 | step 28900 |  ms/b 772.68 | train loss 0.00033369 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 75 | step 28950 |  ms/b 773.10 | train loss 0.00033422 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 75 | step 29000 |  ms/b 783.49 | train loss 0.00035080 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 76 | step 29050 |  ms/b 782.68 | train loss 0.00038170 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 76 | step 29100 |  ms/b 783.75 | train loss 0.00034238 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 76 | step 29150 |  ms/b 780.97 | train loss 0.00034026 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 76 | step 29200 |  ms/b 777.51 | train loss 0.00037807 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 76 | step 29250 |  ms/b 781.21 | train loss 0.00026539 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 76 | step 29300 |  ms/b 784.65 | train loss 0.00023322 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 76 | step 29350 |  ms/b 783.64 | train loss 0.00027782 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 76 | step 29400 |  ms/b 783.40 | train loss 0.00032828 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 77 | step 29450 |  ms/b 783.45 | train loss 0.00031611 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 77 | step 29500 |  ms/b 783.30 | train loss 0.00025981 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 77 | step 29550 |  ms/b 786.77 | train loss 0.00029553 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 77 | step 29600 |  ms/b 787.38 | train loss 0.00028560 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 77 | step 29650 |  ms/b 783.76 | train loss 0.00037260 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 77 | step 29700 |  ms/b 785.10 | train loss 0.00020637 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 77 | step 29750 |  ms/b 786.36 | train loss 0.00033190 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 78 | step 29800 |  ms/b 784.14 | train loss 0.00033307 | NA acc: 0.99 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 78 | step 29850 |  ms/b 784.62 | train loss 0.00027553 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 78 | step 29900 |  ms/b 783.53 | train loss 0.00022103 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 78 | step 29950 |  ms/b 791.41 | train loss 0.00031659 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 78 | step 30000 |  ms/b 786.19 | train loss 0.00024632 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 78 | step 30050 |  ms/b 788.44 | train loss 0.00027269 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 78 | step 30100 |  ms/b 788.96 | train loss 0.00025005 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 78 | step 30150 |  ms/b 790.83 | train loss 0.00023740 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 79 | step 30200 |  ms/b 783.92 | train loss 0.00033390 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 79 | step 30250 |  ms/b 782.03 | train loss 0.00025551 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 79 | step 30300 |  ms/b 780.20 | train loss 0.00035264 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 79 | step 30350 |  ms/b 787.92 | train loss 0.00035149 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 79 | step 30400 |  ms/b 785.65 | train loss 0.00028126 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 79 | step 30450 |  ms/b 784.89 | train loss 0.00023024 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 79 | step 30500 |  ms/b 785.26 | train loss 0.00026441 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 79 | step 30550 |  ms/b 786.91 | train loss 0.00023851 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.44\ntotal_recall 12323\npredicted as zero 380434\ntotal ins num 395726\ntop1_acc 7481\nALL  : Theta 0.9207 | F1 0.5565 | AUC 0.5295\nIgnore ma_f1 0.5343 | input_theta 0.9207 test_result F1 0.5334 | AUC 0.4975\n| epoch  79 | time: 193.88s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 80 | step 30600 |  ms/b 4648.24 | train loss 0.00018530 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 80 | step 30650 |  ms/b 750.05 | train loss 0.00021026 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 80 | step 30700 |  ms/b 757.86 | train loss 0.00023892 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 80 | step 30750 |  ms/b 769.73 | train loss 0.00018390 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 80 | step 30800 |  ms/b 775.34 | train loss 0.00019943 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 80 | step 30850 |  ms/b 779.58 | train loss 0.00019661 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 80 | step 30900 |  ms/b 784.16 | train loss 0.00026078 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 81 | step 30950 |  ms/b 780.88 | train loss 0.00029613 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 81 | step 31000 |  ms/b 780.07 | train loss 0.00023569 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 81 | step 31050 |  ms/b 785.98 | train loss 0.00022552 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 81 | step 31100 |  ms/b 785.14 | train loss 0.00029770 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 81 | step 31150 |  ms/b 783.66 | train loss 0.00018482 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 81 | step 31200 |  ms/b 784.38 | train loss 0.00020585 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 81 | step 31250 |  ms/b 781.09 | train loss 0.00020608 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 81 | step 31300 |  ms/b 790.87 | train loss 0.00021120 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 82 | step 31350 |  ms/b 778.09 | train loss 0.00029092 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 82 | step 31400 |  ms/b 782.62 | train loss 0.00030927 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 82 | step 31450 |  ms/b 790.90 | train loss 0.00035021 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 82 | step 31500 |  ms/b 781.71 | train loss 0.00027054 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 82 | step 31550 |  ms/b 786.56 | train loss 0.00023623 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 82 | step 31600 |  ms/b 787.56 | train loss 0.00048420 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 82 | step 31650 |  ms/b 787.65 | train loss 0.00033094 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 82 | step 31700 |  ms/b 778.85 | train loss 0.00026063 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 83 | step 31750 |  ms/b 780.68 | train loss 0.00024615 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 83 | step 31800 |  ms/b 791.60 | train loss 0.00030920 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 83 | step 31850 |  ms/b 787.02 | train loss 0.00026484 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 83 | step 31900 |  ms/b 785.14 | train loss 0.00027975 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 83 | step 31950 |  ms/b 782.50 | train loss 0.00029860 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 83 | step 32000 |  ms/b 780.33 | train loss 0.00027519 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 83 | step 32050 |  ms/b 783.89 | train loss 0.00024838 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 84 | step 32100 |  ms/b 780.40 | train loss 0.00025997 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 84 | step 32150 |  ms/b 783.83 | train loss 0.00029698 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 84 | step 32200 |  ms/b 782.55 | train loss 0.00024696 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 84 | step 32250 |  ms/b 782.00 | train loss 0.00024649 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 84 | step 32300 |  ms/b 776.55 | train loss 0.00032404 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 84 | step 32350 |  ms/b 782.28 | train loss 0.00023969 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 84 | step 32400 |  ms/b 779.52 | train loss 0.00030086 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 84 | step 32450 |  ms/b 782.91 | train loss 0.00017985 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.09\ntotal_recall 12323\npredicted as zero 382964\ntotal ins num 395726\ntop1_acc 6921\nALL  : Theta 0.8108 | F1 0.5563 | AUC 0.5203\nIgnore ma_f1 0.5331 | input_theta 0.8108 test_result F1 0.5327 | AUC 0.4836\n| epoch  84 | time: 191.75s\n-----------------------------------------------------------------------------------------\n| epoch 85 | step 32500 |  ms/b 4585.74 | train loss 0.00022900 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 85 | step 32550 |  ms/b 742.06 | train loss 0.00021657 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 85 | step 32600 |  ms/b 753.33 | train loss 0.00041255 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 85 | step 32650 |  ms/b 763.28 | train loss 0.00032845 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 85 | step 32700 |  ms/b 769.53 | train loss 0.00025120 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 85 | step 32750 |  ms/b 777.80 | train loss 0.00026761 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 85 | step 32800 |  ms/b 782.40 | train loss 0.00017936 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 85 | step 32850 |  ms/b 780.26 | train loss 0.00023038 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 86 | step 32900 |  ms/b 777.79 | train loss 0.00020430 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 86 | step 32950 |  ms/b 785.82 | train loss 0.00027782 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 86 | step 33000 |  ms/b 779.51 | train loss 0.00026463 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 86 | step 33050 |  ms/b 781.42 | train loss 0.00025696 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 86 | step 33100 |  ms/b 787.27 | train loss 0.00040947 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 86 | step 33150 |  ms/b 782.51 | train loss 0.00021195 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 86 | step 33200 |  ms/b 783.44 | train loss 0.00029641 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 87 | step 33250 |  ms/b 778.35 | train loss 0.00028169 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 87 | step 33300 |  ms/b 785.31 | train loss 0.00020389 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 87 | step 33350 |  ms/b 783.24 | train loss 0.00025459 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 87 | step 33400 |  ms/b 785.99 | train loss 0.00022493 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 87 | step 33450 |  ms/b 783.20 | train loss 0.00016100 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 87 | step 33500 |  ms/b 788.01 | train loss 0.00021874 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 87 | step 33550 |  ms/b 779.80 | train loss 0.00020985 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 87 | step 33600 |  ms/b 785.58 | train loss 0.00015411 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 88 | step 33650 |  ms/b 781.67 | train loss 0.00021129 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 88 | step 33700 |  ms/b 785.41 | train loss 0.00023003 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 88 | step 33750 |  ms/b 781.08 | train loss 0.00018190 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 88 | step 33800 |  ms/b 785.10 | train loss 0.00017699 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 88 | step 33850 |  ms/b 783.22 | train loss 0.00015159 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 88 | step 33900 |  ms/b 784.42 | train loss 0.00016216 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 88 | step 33950 |  ms/b 791.06 | train loss 0.00014396 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 89 | step 34000 |  ms/b 775.76 | train loss 0.00016130 | NA acc: 1.00 | not NA acc: 1.00  | tot acc: 1.00 \n| epoch 89 | step 34050 |  ms/b 786.68 | train loss 0.00014984 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 89 | step 34100 |  ms/b 785.12 | train loss 0.00020410 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 89 | step 34150 |  ms/b 783.13 | train loss 0.00018397 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 89 | step 34200 |  ms/b 787.18 | train loss 0.00011922 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 89 | step 34250 |  ms/b 786.20 | train loss 0.00018128 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 89 | step 34300 |  ms/b 789.64 | train loss 0.00017045 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 89 | step 34350 |  ms/b 787.53 | train loss 0.00019656 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.00\ntotal_recall 12323\npredicted as zero 382213\ntotal ins num 395726\ntop1_acc 7102\nALL  : Theta 0.7632 | F1 0.5585 | AUC 0.5277\nIgnore ma_f1 0.5357 | input_theta 0.7632 test_result F1 0.5342 | AUC 0.4930\n| epoch  89 | time: 192.92s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 90 | step 34400 |  ms/b 4651.01 | train loss 0.00015857 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 90 | step 34450 |  ms/b 737.99 | train loss 0.00017922 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 90 | step 34500 |  ms/b 757.33 | train loss 0.00018202 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 90 | step 34550 |  ms/b 764.10 | train loss 0.00014048 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 90 | step 34600 |  ms/b 772.15 | train loss 0.00023534 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 90 | step 34650 |  ms/b 773.55 | train loss 0.00022033 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 90 | step 34700 |  ms/b 782.68 | train loss 0.00033671 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 90 | step 34750 |  ms/b 780.57 | train loss 0.00020391 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 91 | step 34800 |  ms/b 776.34 | train loss 0.00015783 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 91 | step 34850 |  ms/b 783.28 | train loss 0.00018170 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 91 | step 34900 |  ms/b 785.89 | train loss 0.00017635 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 91 | step 34950 |  ms/b 781.44 | train loss 0.00020642 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 91 | step 35000 |  ms/b 783.12 | train loss 0.00021673 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 91 | step 35050 |  ms/b 782.96 | train loss 0.00023498 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 91 | step 35100 |  ms/b 787.00 | train loss 0.00016753 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 92 | step 35150 |  ms/b 783.47 | train loss 0.00017955 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 92 | step 35200 |  ms/b 785.81 | train loss 0.00019485 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 92 | step 35250 |  ms/b 782.59 | train loss 0.00019623 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 92 | step 35300 |  ms/b 786.70 | train loss 0.00023076 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 92 | step 35350 |  ms/b 790.29 | train loss 0.00024555 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 92 | step 35400 |  ms/b 785.16 | train loss 0.00029755 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 92 | step 35450 |  ms/b 787.37 | train loss 0.00019204 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 92 | step 35500 |  ms/b 786.16 | train loss 0.00019371 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 93 | step 35550 |  ms/b 781.72 | train loss 0.00022966 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 93 | step 35600 |  ms/b 787.29 | train loss 0.00023638 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 93 | step 35650 |  ms/b 792.46 | train loss 0.00021088 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 93 | step 35700 |  ms/b 781.18 | train loss 0.00018630 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 93 | step 35750 |  ms/b 784.73 | train loss 0.00016854 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 93 | step 35800 |  ms/b 786.65 | train loss 0.00016510 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 93 | step 35850 |  ms/b 781.97 | train loss 0.00020992 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 93 | step 35900 |  ms/b 784.46 | train loss 0.00024081 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 94 | step 35950 |  ms/b 782.80 | train loss 0.00026539 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 94 | step 36000 |  ms/b 783.78 | train loss 0.00017748 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 94 | step 36050 |  ms/b 785.13 | train loss 0.00019204 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 94 | step 36100 |  ms/b 789.06 | train loss 0.00021194 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 94 | step 36150 |  ms/b 783.19 | train loss 0.00020688 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 94 | step 36200 |  ms/b 782.94 | train loss 0.00020383 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 94 | step 36250 |  ms/b 775.37 | train loss 0.00015899 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 77.80\ntotal_recall 12323\npredicted as zero 383124\ntotal ins num 395726\ntop1_acc 6838\nALL  : Theta 0.7290 | F1 0.5545 | AUC 0.5198\nIgnore ma_f1 0.5312 | input_theta 0.7290 test_result F1 0.5306 | AUC 0.4855\n| epoch  94 | time: 192.33s\n-----------------------------------------------------------------------------------------\n| epoch 95 | step 36300 |  ms/b 4615.37 | train loss 0.00018508 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 95 | step 36350 |  ms/b 742.92 | train loss 0.00018271 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 95 | step 36400 |  ms/b 753.02 | train loss 0.00017736 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 95 | step 36450 |  ms/b 764.70 | train loss 0.00018643 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 95 | step 36500 |  ms/b 771.79 | train loss 0.00014609 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 95 | step 36550 |  ms/b 769.44 | train loss 0.00019745 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 95 | step 36600 |  ms/b 776.97 | train loss 0.00015990 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 95 | step 36650 |  ms/b 781.86 | train loss 0.00017853 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 96 | step 36700 |  ms/b 779.46 | train loss 0.00013408 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 96 | step 36750 |  ms/b 781.60 | train loss 0.00019784 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 96 | step 36800 |  ms/b 781.38 | train loss 0.00021536 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 96 | step 36850 |  ms/b 792.34 | train loss 0.00015382 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 96 | step 36900 |  ms/b 782.08 | train loss 0.00011174 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 96 | step 36950 |  ms/b 786.74 | train loss 0.00021265 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 96 | step 37000 |  ms/b 781.92 | train loss 0.00021013 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 96 | step 37050 |  ms/b 780.99 | train loss 0.00012786 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 97 | step 37100 |  ms/b 783.56 | train loss 0.00015244 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 97 | step 37150 |  ms/b 784.46 | train loss 0.00012155 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 97 | step 37200 |  ms/b 785.86 | train loss 0.00022842 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 97 | step 37250 |  ms/b 784.36 | train loss 0.00019961 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 97 | step 37300 |  ms/b 786.65 | train loss 0.00021122 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 97 | step 37350 |  ms/b 781.38 | train loss 0.00016019 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 97 | step 37400 |  ms/b 785.06 | train loss 0.00018906 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 98 | step 37450 |  ms/b 787.21 | train loss 0.00016773 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 98 | step 37500 |  ms/b 784.06 | train loss 0.00030280 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 98 | step 37550 |  ms/b 790.81 | train loss 0.00021119 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 98 | step 37600 |  ms/b 785.29 | train loss 0.00016459 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 98 | step 37650 |  ms/b 778.15 | train loss 0.00032339 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 98 | step 37700 |  ms/b 782.57 | train loss 0.00016337 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 98 | step 37750 |  ms/b 791.18 | train loss 0.00017545 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 98 | step 37800 |  ms/b 782.25 | train loss 0.00020164 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 99 | step 37850 |  ms/b 779.80 | train loss 0.00010220 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 99 | step 37900 |  ms/b 781.27 | train loss 0.00017457 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 99 | step 37950 |  ms/b 777.63 | train loss 0.00022392 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 99 | step 38000 |  ms/b 786.36 | train loss 0.00014425 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 99 | step 38050 |  ms/b 778.92 | train loss 0.00016659 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 99 | step 38100 |  ms/b 783.68 | train loss 0.00012832 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 99 | step 38150 |  ms/b 780.63 | train loss 0.00018964 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 99 | step 38200 |  ms/b 772.14 | train loss 0.00017239 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.07\ntotal_recall 12323\npredicted as zero 381878\ntotal ins num 395726\ntop1_acc 7162\nALL  : Theta 0.8512 | F1 0.5580 | AUC 0.5283\nIgnore ma_f1 0.5362 | input_theta 0.8512 test_result F1 0.5350 | AUC 0.4974\n| epoch  99 | time: 193.69s\n-----------------------------------------------------------------------------------------\n| epoch 100 | step 38250 |  ms/b 4611.08 | train loss 0.00009019 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 100 | step 38300 |  ms/b 753.83 | train loss 0.00016893 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 100 | step 38350 |  ms/b 762.62 | train loss 0.00012394 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 100 | step 38400 |  ms/b 772.52 | train loss 0.00021500 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 100 | step 38450 |  ms/b 774.25 | train loss 0.00018633 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 100 | step 38500 |  ms/b 777.94 | train loss 0.00015659 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 100 | step 38550 |  ms/b 778.16 | train loss 0.00016266 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 101 | step 38600 |  ms/b 785.52 | train loss 0.00016062 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 101 | step 38650 |  ms/b 783.43 | train loss 0.00015228 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 101 | step 38700 |  ms/b 786.43 | train loss 0.00012221 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 101 | step 38750 |  ms/b 784.87 | train loss 0.00014584 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 101 | step 38800 |  ms/b 787.91 | train loss 0.00013619 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 101 | step 38850 |  ms/b 788.35 | train loss 0.00008687 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 101 | step 38900 |  ms/b 782.55 | train loss 0.00011869 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 101 | step 38950 |  ms/b 780.51 | train loss 0.00011210 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 102 | step 39000 |  ms/b 791.38 | train loss 0.00013880 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 102 | step 39050 |  ms/b 788.38 | train loss 0.00010844 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 102 | step 39100 |  ms/b 782.67 | train loss 0.00014476 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 102 | step 39150 |  ms/b 781.12 | train loss 0.00017282 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 102 | step 39200 |  ms/b 780.53 | train loss 0.00016268 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 102 | step 39250 |  ms/b 779.47 | train loss 0.00015808 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 102 | step 39300 |  ms/b 781.03 | train loss 0.00012531 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 103 | step 39350 |  ms/b 782.73 | train loss 0.00010677 | NA acc: 1.00 | not NA acc: 0.98  | tot acc: 0.99 \n| epoch 103 | step 39400 |  ms/b 782.01 | train loss 0.00015803 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 103 | step 39450 |  ms/b 780.37 | train loss 0.00018540 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 103 | step 39500 |  ms/b 785.83 | train loss 0.00013412 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 103 | step 39550 |  ms/b 779.20 | train loss 0.00015252 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 103 | step 39600 |  ms/b 785.20 | train loss 0.00017025 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 103 | step 39650 |  ms/b 780.50 | train loss 0.00013191 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 103 | step 39700 |  ms/b 777.40 | train loss 0.00011516 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 104 | step 39750 |  ms/b 779.76 | train loss 0.00011612 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 104 | step 39800 |  ms/b 787.04 | train loss 0.00013043 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 104 | step 39850 |  ms/b 776.23 | train loss 0.00012805 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 104 | step 39900 |  ms/b 781.96 | train loss 0.00018663 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 104 | step 39950 |  ms/b 780.85 | train loss 0.00013633 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 104 | step 40000 |  ms/b 784.90 | train loss 0.00017002 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 104 | step 40050 |  ms/b 783.00 | train loss 0.00014704 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 104 | step 40100 |  ms/b 783.62 | train loss 0.00014539 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 77.81\ntotal_recall 12323\npredicted as zero 384086\ntotal ins num 395726\ntop1_acc 6660\nALL  : Theta 0.5114 | F1 0.5575 | AUC 0.5264\nIgnore ma_f1 0.5355 | input_theta 0.5114 test_result F1 0.5332 | AUC 0.4961\n| epoch 104 | time: 192.72s\n-----------------------------------------------------------------------------------------\n| epoch 105 | step 40150 |  ms/b 4596.62 | train loss 0.00015615 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 105 | step 40200 |  ms/b 754.76 | train loss 0.00012767 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 105 | step 40250 |  ms/b 756.12 | train loss 0.00012120 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 105 | step 40300 |  ms/b 771.90 | train loss 0.00017226 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 105 | step 40350 |  ms/b 773.69 | train loss 0.00015752 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 105 | step 40400 |  ms/b 777.08 | train loss 0.00010088 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 105 | step 40450 |  ms/b 781.48 | train loss 0.00013475 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 106 | step 40500 |  ms/b 782.96 | train loss 0.00014695 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 106 | step 40550 |  ms/b 785.56 | train loss 0.00011850 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 106 | step 40600 |  ms/b 779.99 | train loss 0.00008288 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 106 | step 40650 |  ms/b 782.88 | train loss 0.00013948 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 106 | step 40700 |  ms/b 782.93 | train loss 0.00008931 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 106 | step 40750 |  ms/b 789.02 | train loss 0.00013155 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 106 | step 40800 |  ms/b 787.40 | train loss 0.00010195 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 106 | step 40850 |  ms/b 785.61 | train loss 0.00008339 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 107 | step 40900 |  ms/b 781.12 | train loss 0.00008069 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 107 | step 40950 |  ms/b 786.29 | train loss 0.00009743 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 107 | step 41000 |  ms/b 785.19 | train loss 0.00012512 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 107 | step 41050 |  ms/b 781.84 | train loss 0.00010652 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 107 | step 41100 |  ms/b 786.86 | train loss 0.00011011 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 107 | step 41150 |  ms/b 779.85 | train loss 0.00007163 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 107 | step 41200 |  ms/b 786.31 | train loss 0.00012749 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 107 | step 41250 |  ms/b 780.05 | train loss 0.00010309 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 108 | step 41300 |  ms/b 784.76 | train loss 0.00010712 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 108 | step 41350 |  ms/b 787.37 | train loss 0.00012848 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 108 | step 41400 |  ms/b 783.29 | train loss 0.00007178 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 108 | step 41450 |  ms/b 787.02 | train loss 0.00012351 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 108 | step 41500 |  ms/b 790.22 | train loss 0.00012001 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 108 | step 41550 |  ms/b 786.55 | train loss 0.00007227 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 108 | step 41600 |  ms/b 788.17 | train loss 0.00014371 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 109 | step 41650 |  ms/b 782.04 | train loss 0.00013953 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 109 | step 41700 |  ms/b 781.86 | train loss 0.00011964 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 109 | step 41750 |  ms/b 784.95 | train loss 0.00011852 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 109 | step 41800 |  ms/b 787.39 | train loss 0.00017296 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 109 | step 41850 |  ms/b 785.99 | train loss 0.00013850 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 109 | step 41900 |  ms/b 786.31 | train loss 0.00016459 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 109 | step 41950 |  ms/b 784.32 | train loss 0.00014081 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 109 | step 42000 |  ms/b 782.96 | train loss 0.00009420 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.16\ntotal_recall 12323\npredicted as zero 382382\ntotal ins num 395726\ntop1_acc 7069\nALL  : Theta 0.9011 | F1 0.5578 | AUC 0.5247\nIgnore ma_f1 0.5361 | input_theta 0.9011 test_result F1 0.5355 | AUC 0.4919\n| epoch 109 | time: 193.37s\n-----------------------------------------------------------------------------------------\n| epoch 110 | step 42050 |  ms/b 4616.09 | train loss 0.00009608 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 110 | step 42100 |  ms/b 747.37 | train loss 0.00021854 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 110 | step 42150 |  ms/b 757.54 | train loss 0.00018367 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 110 | step 42200 |  ms/b 763.87 | train loss 0.00016997 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 110 | step 42250 |  ms/b 770.39 | train loss 0.00013641 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 110 | step 42300 |  ms/b 780.11 | train loss 0.00013116 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 110 | step 42350 |  ms/b 783.12 | train loss 0.00011436 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 110 | step 42400 |  ms/b 786.65 | train loss 0.00014818 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 111 | step 42450 |  ms/b 778.74 | train loss 0.00018706 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 111 | step 42500 |  ms/b 790.19 | train loss 0.00012570 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 111 | step 42550 |  ms/b 781.55 | train loss 0.00010713 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 111 | step 42600 |  ms/b 780.27 | train loss 0.00013050 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 111 | step 42650 |  ms/b 790.61 | train loss 0.00010459 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 111 | step 42700 |  ms/b 788.09 | train loss 0.00012284 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 111 | step 42750 |  ms/b 791.25 | train loss 0.00010030 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 112 | step 42800 |  ms/b 785.62 | train loss 0.00010734 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 112 | step 42850 |  ms/b 789.48 | train loss 0.00014158 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 112 | step 42900 |  ms/b 784.93 | train loss 0.00009179 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 112 | step 42950 |  ms/b 785.76 | train loss 0.00014079 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 112 | step 43000 |  ms/b 788.98 | train loss 0.00014579 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 112 | step 43050 |  ms/b 787.57 | train loss 0.00010147 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 112 | step 43100 |  ms/b 788.25 | train loss 0.00010084 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 112 | step 43150 |  ms/b 783.86 | train loss 0.00011843 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 113 | step 43200 |  ms/b 790.89 | train loss 0.00018290 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 113 | step 43250 |  ms/b 788.25 | train loss 0.00006968 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 113 | step 43300 |  ms/b 783.95 | train loss 0.00007257 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 113 | step 43350 |  ms/b 783.16 | train loss 0.00010782 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 113 | step 43400 |  ms/b 789.91 | train loss 0.00012575 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 113 | step 43450 |  ms/b 791.09 | train loss 0.00009864 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 113 | step 43500 |  ms/b 788.80 | train loss 0.00013400 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 114 | step 43550 |  ms/b 781.38 | train loss 0.00007157 | NA acc: 1.00 | not NA acc: 0.99  | tot acc: 1.00 \n| epoch 114 | step 43600 |  ms/b 785.73 | train loss 0.00011537 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 114 | step 43650 |  ms/b 788.48 | train loss 0.00013858 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 114 | step 43700 |  ms/b 783.38 | train loss 0.00011932 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 114 | step 43750 |  ms/b 786.61 | train loss 0.00010268 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 114 | step 43800 |  ms/b 783.93 | train loss 0.00010434 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 114 | step 43850 |  ms/b 786.04 | train loss 0.00009092 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 114 | step 43900 |  ms/b 786.62 | train loss 0.00007275 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.11\ntotal_recall 12323\npredicted as zero 383353\ntotal ins num 395726\ntop1_acc 6811\nALL  : Theta 0.6055 | F1 0.5565 | AUC 0.5231\nIgnore ma_f1 0.5331 | input_theta 0.6055 test_result F1 0.5317 | AUC 0.4899\n| epoch 114 | time: 194.01s\n-----------------------------------------------------------------------------------------\n| epoch 115 | step 43950 |  ms/b 4640.67 | train loss 0.00006887 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 115 | step 44000 |  ms/b 743.78 | train loss 0.00008619 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 115 | step 44050 |  ms/b 758.62 | train loss 0.00008743 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 115 | step 44100 |  ms/b 766.59 | train loss 0.00008838 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 115 | step 44150 |  ms/b 769.69 | train loss 0.00008505 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 115 | step 44200 |  ms/b 774.97 | train loss 0.00006939 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 115 | step 44250 |  ms/b 781.32 | train loss 0.00012115 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 115 | step 44300 |  ms/b 782.45 | train loss 0.00010969 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 116 | step 44350 |  ms/b 782.35 | train loss 0.00007414 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 116 | step 44400 |  ms/b 784.33 | train loss 0.00009181 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 116 | step 44450 |  ms/b 784.68 | train loss 0.00012523 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 116 | step 44500 |  ms/b 786.35 | train loss 0.00005359 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 116 | step 44550 |  ms/b 787.13 | train loss 0.00007273 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 116 | step 44600 |  ms/b 789.44 | train loss 0.00008929 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 116 | step 44650 |  ms/b 791.88 | train loss 0.00008275 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 117 | step 44700 |  ms/b 785.63 | train loss 0.00007326 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 117 | step 44750 |  ms/b 785.86 | train loss 0.00007534 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 117 | step 44800 |  ms/b 786.37 | train loss 0.00007927 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 117 | step 44850 |  ms/b 787.66 | train loss 0.00012235 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 117 | step 44900 |  ms/b 791.79 | train loss 0.00010823 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 117 | step 44950 |  ms/b 786.00 | train loss 0.00010835 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 117 | step 45000 |  ms/b 784.12 | train loss 0.00012818 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 117 | step 45050 |  ms/b 790.44 | train loss 0.00013045 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 118 | step 45100 |  ms/b 792.50 | train loss 0.00012125 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 118 | step 45150 |  ms/b 791.05 | train loss 0.00012035 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 118 | step 45200 |  ms/b 786.12 | train loss 0.00013998 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 118 | step 45250 |  ms/b 788.41 | train loss 0.00010471 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 118 | step 45300 |  ms/b 794.04 | train loss 0.00010070 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 118 | step 45350 |  ms/b 789.74 | train loss 0.00007470 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 118 | step 45400 |  ms/b 786.61 | train loss 0.00008100 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 118 | step 45450 |  ms/b 790.48 | train loss 0.00009427 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 119 | step 45500 |  ms/b 783.34 | train loss 0.00008942 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 119 | step 45550 |  ms/b 789.29 | train loss 0.00010471 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 119 | step 45600 |  ms/b 779.45 | train loss 0.00007580 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 119 | step 45650 |  ms/b 785.87 | train loss 0.00012148 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 119 | step 45700 |  ms/b 788.27 | train loss 0.00008684 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 119 | step 45750 |  ms/b 782.17 | train loss 0.00007034 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 119 | step 45800 |  ms/b 789.54 | train loss 0.00006744 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.14\ntotal_recall 12323\npredicted as zero 383198\ntotal ins num 395726\ntop1_acc 6854\nALL  : Theta 0.8145 | F1 0.5593 | AUC 0.5298\nIgnore ma_f1 0.5367 | input_theta 0.8145 test_result F1 0.5365 | AUC 0.4962\n| epoch 119 | time: 193.82s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 120 | step 45850 |  ms/b 4682.13 | train loss 0.00008857 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 120 | step 45900 |  ms/b 741.46 | train loss 0.00008403 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 120 | step 45950 |  ms/b 749.22 | train loss 0.00006791 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 120 | step 46000 |  ms/b 766.43 | train loss 0.00005620 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 120 | step 46050 |  ms/b 775.68 | train loss 0.00008178 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 120 | step 46100 |  ms/b 779.57 | train loss 0.00007324 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 120 | step 46150 |  ms/b 779.50 | train loss 0.00007718 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 120 | step 46200 |  ms/b 786.74 | train loss 0.00010163 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 121 | step 46250 |  ms/b 781.62 | train loss 0.00006477 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 121 | step 46300 |  ms/b 788.59 | train loss 0.00011238 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 121 | step 46350 |  ms/b 783.13 | train loss 0.00010771 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 121 | step 46400 |  ms/b 793.62 | train loss 0.00009750 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 121 | step 46450 |  ms/b 790.13 | train loss 0.00007398 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 121 | step 46500 |  ms/b 789.44 | train loss 0.00012827 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 121 | step 46550 |  ms/b 786.20 | train loss 0.00011963 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 121 | step 46600 |  ms/b 781.40 | train loss 0.00006339 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 122 | step 46650 |  ms/b 785.36 | train loss 0.00007636 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 122 | step 46700 |  ms/b 779.08 | train loss 0.00010098 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 122 | step 46750 |  ms/b 777.49 | train loss 0.00008426 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 122 | step 46800 |  ms/b 775.97 | train loss 0.00007408 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 122 | step 46850 |  ms/b 786.45 | train loss 0.00009528 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 122 | step 46900 |  ms/b 783.94 | train loss 0.00009164 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 122 | step 46950 |  ms/b 784.55 | train loss 0.00006173 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 123 | step 47000 |  ms/b 781.86 | train loss 0.00010342 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 123 | step 47050 |  ms/b 786.87 | train loss 0.00011979 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 123 | step 47100 |  ms/b 778.35 | train loss 0.00012430 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 123 | step 47150 |  ms/b 785.64 | train loss 0.00007877 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 123 | step 47200 |  ms/b 789.08 | train loss 0.00008012 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 123 | step 47250 |  ms/b 786.75 | train loss 0.00006200 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 123 | step 47300 |  ms/b 784.97 | train loss 0.00007147 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 123 | step 47350 |  ms/b 781.84 | train loss 0.00007861 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 124 | step 47400 |  ms/b 786.23 | train loss 0.00004746 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 124 | step 47450 |  ms/b 779.10 | train loss 0.00007159 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 124 | step 47500 |  ms/b 786.16 | train loss 0.00007592 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 124 | step 47550 |  ms/b 785.44 | train loss 0.00008899 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 124 | step 47600 |  ms/b 783.44 | train loss 0.00006916 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 124 | step 47650 |  ms/b 782.71 | train loss 0.00008507 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 124 | step 47700 |  ms/b 780.80 | train loss 0.00009797 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 124 | step 47750 |  ms/b 774.96 | train loss 0.00006289 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.33\ntotal_recall 12323\npredicted as zero 383071\ntotal ins num 395726\ntop1_acc 6889\nALL  : Theta 0.8824 | F1 0.5589 | AUC 0.5303\nIgnore ma_f1 0.5377 | input_theta 0.8824 test_result F1 0.5374 | AUC 0.4982\n| epoch 124 | time: 194.02s\n-----------------------------------------------------------------------------------------\n| epoch 125 | step 47800 |  ms/b 4624.61 | train loss 0.00006733 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 125 | step 47850 |  ms/b 750.24 | train loss 0.00006982 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 125 | step 47900 |  ms/b 761.87 | train loss 0.00008531 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 125 | step 47950 |  ms/b 772.15 | train loss 0.00009107 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 125 | step 48000 |  ms/b 772.82 | train loss 0.00007493 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 125 | step 48050 |  ms/b 783.00 | train loss 0.00007112 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 125 | step 48100 |  ms/b 779.39 | train loss 0.00006486 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 126 | step 48150 |  ms/b 781.82 | train loss 0.00008092 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 126 | step 48200 |  ms/b 784.06 | train loss 0.00003449 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 126 | step 48250 |  ms/b 785.71 | train loss 0.00007766 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 126 | step 48300 |  ms/b 786.62 | train loss 0.00005759 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 126 | step 48350 |  ms/b 785.67 | train loss 0.00008203 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 126 | step 48400 |  ms/b 789.54 | train loss 0.00008244 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 126 | step 48450 |  ms/b 794.97 | train loss 0.00006838 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 126 | step 48500 |  ms/b 786.92 | train loss 0.00006756 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 127 | step 48550 |  ms/b 783.11 | train loss 0.00008390 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 127 | step 48600 |  ms/b 787.40 | train loss 0.00005128 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 127 | step 48650 |  ms/b 790.38 | train loss 0.00014204 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 127 | step 48700 |  ms/b 787.16 | train loss 0.00005414 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 127 | step 48750 |  ms/b 790.22 | train loss 0.00005299 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 127 | step 48800 |  ms/b 784.01 | train loss 0.00010151 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 127 | step 48850 |  ms/b 787.31 | train loss 0.00012482 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 128 | step 48900 |  ms/b 783.91 | train loss 0.00004488 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 128 | step 48950 |  ms/b 781.88 | train loss 0.00005399 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 128 | step 49000 |  ms/b 780.21 | train loss 0.00006356 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 128 | step 49050 |  ms/b 779.41 | train loss 0.00011306 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 128 | step 49100 |  ms/b 779.45 | train loss 0.00010592 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 128 | step 49150 |  ms/b 782.00 | train loss 0.00005896 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 128 | step 49200 |  ms/b 780.18 | train loss 0.00006668 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 128 | step 49250 |  ms/b 782.66 | train loss 0.00006431 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 129 | step 49300 |  ms/b 773.60 | train loss 0.00008949 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 129 | step 49350 |  ms/b 784.81 | train loss 0.00019522 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 129 | step 49400 |  ms/b 777.73 | train loss 0.00011629 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 129 | step 49450 |  ms/b 779.04 | train loss 0.00009278 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 129 | step 49500 |  ms/b 786.43 | train loss 0.00008982 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 129 | step 49550 |  ms/b 782.30 | train loss 0.00005230 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 129 | step 49600 |  ms/b 779.31 | train loss 0.00008564 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 129 | step 49650 |  ms/b 786.95 | train loss 0.00005294 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.22\ntotal_recall 12323\npredicted as zero 383564\ntotal ins num 395726\ntop1_acc 6735\nALL  : Theta 0.6117 | F1 0.5600 | AUC 0.5271\nIgnore ma_f1 0.5363 | input_theta 0.6117 test_result F1 0.5347 | AUC 0.4925\n| epoch 129 | time: 193.72s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 130 | step 49700 |  ms/b 4646.77 | train loss 0.00006448 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 130 | step 49750 |  ms/b 751.35 | train loss 0.00007848 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 130 | step 49800 |  ms/b 760.80 | train loss 0.00007811 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 130 | step 49850 |  ms/b 769.78 | train loss 0.00009800 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 130 | step 49900 |  ms/b 772.13 | train loss 0.00005330 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 130 | step 49950 |  ms/b 783.12 | train loss 0.00009879 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 130 | step 50000 |  ms/b 781.16 | train loss 0.00005551 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 131 | step 50050 |  ms/b 782.31 | train loss 0.00003769 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 131 | step 50100 |  ms/b 784.94 | train loss 0.00004949 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 131 | step 50150 |  ms/b 777.15 | train loss 0.00004217 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 131 | step 50200 |  ms/b 781.94 | train loss 0.00007983 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 131 | step 50250 |  ms/b 779.95 | train loss 0.00006305 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 131 | step 50300 |  ms/b 785.12 | train loss 0.00003975 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 131 | step 50350 |  ms/b 786.61 | train loss 0.00006380 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 131 | step 50400 |  ms/b 790.62 | train loss 0.00006331 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 132 | step 50450 |  ms/b 779.74 | train loss 0.00004346 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 132 | step 50500 |  ms/b 786.37 | train loss 0.00005642 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 132 | step 50550 |  ms/b 785.45 | train loss 0.00005136 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 132 | step 50600 |  ms/b 785.83 | train loss 0.00007004 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 132 | step 50650 |  ms/b 786.98 | train loss 0.00006557 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 132 | step 50700 |  ms/b 791.01 | train loss 0.00008002 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 132 | step 50750 |  ms/b 793.88 | train loss 0.00006308 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 132 | step 50800 |  ms/b 788.98 | train loss 0.00006842 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 133 | step 50850 |  ms/b 784.54 | train loss 0.00007405 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 133 | step 50900 |  ms/b 784.93 | train loss 0.00009696 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 133 | step 50950 |  ms/b 785.24 | train loss 0.00007281 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 133 | step 51000 |  ms/b 786.54 | train loss 0.00006679 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 133 | step 51050 |  ms/b 784.10 | train loss 0.00005028 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 133 | step 51100 |  ms/b 778.48 | train loss 0.00009490 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 133 | step 51150 |  ms/b 787.00 | train loss 0.00007229 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 134 | step 51200 |  ms/b 781.21 | train loss 0.00011554 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 134 | step 51250 |  ms/b 779.76 | train loss 0.00005335 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 134 | step 51300 |  ms/b 781.26 | train loss 0.00006442 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 134 | step 51350 |  ms/b 783.37 | train loss 0.00004994 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 134 | step 51400 |  ms/b 783.96 | train loss 0.00007426 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 134 | step 51450 |  ms/b 779.82 | train loss 0.00003586 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 134 | step 51500 |  ms/b 782.07 | train loss 0.00005162 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 134 | step 51550 |  ms/b 783.47 | train loss 0.00007032 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.18\ntotal_recall 12323\npredicted as zero 383986\ntotal ins num 395726\ntop1_acc 6672\nALL  : Theta 0.8374 | F1 0.5619 | AUC 0.5274\nIgnore ma_f1 0.5405 | input_theta 0.8374 test_result F1 0.5404 | AUC 0.4938\n| epoch 134 | time: 193.21s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 135 | step 51600 |  ms/b 4647.22 | train loss 0.00004512 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 135 | step 51650 |  ms/b 744.52 | train loss 0.00003520 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 135 | step 51700 |  ms/b 760.73 | train loss 0.00004857 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 135 | step 51750 |  ms/b 763.99 | train loss 0.00006006 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 135 | step 51800 |  ms/b 781.51 | train loss 0.00008057 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 135 | step 51850 |  ms/b 775.71 | train loss 0.00006691 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 135 | step 51900 |  ms/b 788.29 | train loss 0.00005103 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 135 | step 51950 |  ms/b 784.35 | train loss 0.00017045 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 136 | step 52000 |  ms/b 782.92 | train loss 0.00006660 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 136 | step 52050 |  ms/b 783.73 | train loss 0.00005146 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 136 | step 52100 |  ms/b 787.41 | train loss 0.00015035 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 136 | step 52150 |  ms/b 784.59 | train loss 0.00006934 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 136 | step 52200 |  ms/b 788.32 | train loss 0.00005741 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 136 | step 52250 |  ms/b 788.28 | train loss 0.00004710 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 136 | step 52300 |  ms/b 785.29 | train loss 0.00004369 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 137 | step 52350 |  ms/b 789.32 | train loss 0.00008290 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 137 | step 52400 |  ms/b 793.06 | train loss 0.00003665 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 137 | step 52450 |  ms/b 785.87 | train loss 0.00007624 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 137 | step 52500 |  ms/b 782.82 | train loss 0.00007115 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 137 | step 52550 |  ms/b 790.18 | train loss 0.00007158 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 137 | step 52600 |  ms/b 789.84 | train loss 0.00003391 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 137 | step 52650 |  ms/b 786.16 | train loss 0.00006804 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 137 | step 52700 |  ms/b 788.44 | train loss 0.00004649 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 138 | step 52750 |  ms/b 784.88 | train loss 0.00007002 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 138 | step 52800 |  ms/b 792.01 | train loss 0.00007833 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 138 | step 52850 |  ms/b 789.45 | train loss 0.00005058 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 138 | step 52900 |  ms/b 790.96 | train loss 0.00003732 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 138 | step 52950 |  ms/b 790.29 | train loss 0.00004105 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 138 | step 53000 |  ms/b 782.32 | train loss 0.00004214 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 138 | step 53050 |  ms/b 792.23 | train loss 0.00004355 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 139 | step 53100 |  ms/b 786.12 | train loss 0.00006262 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 139 | step 53150 |  ms/b 785.99 | train loss 0.00005587 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 139 | step 53200 |  ms/b 788.07 | train loss 0.00004758 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 139 | step 53250 |  ms/b 791.08 | train loss 0.00002795 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 139 | step 53300 |  ms/b 787.14 | train loss 0.00006204 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 139 | step 53350 |  ms/b 785.24 | train loss 0.00005265 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 139 | step 53400 |  ms/b 791.44 | train loss 0.00005716 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 139 | step 53450 |  ms/b 789.20 | train loss 0.00006653 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.65\ntotal_recall 12323\npredicted as zero 384470\ntotal ins num 395726\ntop1_acc 6536\nALL  : Theta 0.4628 | F1 0.5614 | AUC 0.5243\nIgnore ma_f1 0.5376 | input_theta 0.4628 test_result F1 0.5374 | AUC 0.4909\n| epoch 139 | time: 194.52s\n-----------------------------------------------------------------------------------------\n| epoch 140 | step 53500 |  ms/b 4655.42 | train loss 0.00007176 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 140 | step 53550 |  ms/b 741.46 | train loss 0.00009490 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 140 | step 53600 |  ms/b 753.38 | train loss 0.00006014 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 140 | step 53650 |  ms/b 769.21 | train loss 0.00008004 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 140 | step 53700 |  ms/b 775.52 | train loss 0.00004344 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 140 | step 53750 |  ms/b 782.65 | train loss 0.00006913 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 140 | step 53800 |  ms/b 785.97 | train loss 0.00007280 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 140 | step 53850 |  ms/b 782.34 | train loss 0.00003934 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 141 | step 53900 |  ms/b 786.70 | train loss 0.00004177 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 141 | step 53950 |  ms/b 784.02 | train loss 0.00009339 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 141 | step 54000 |  ms/b 786.08 | train loss 0.00003662 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 141 | step 54050 |  ms/b 782.20 | train loss 0.00005986 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 141 | step 54100 |  ms/b 791.80 | train loss 0.00006010 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 141 | step 54150 |  ms/b 787.36 | train loss 0.00002703 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 141 | step 54200 |  ms/b 785.69 | train loss 0.00007872 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 142 | step 54250 |  ms/b 789.75 | train loss 0.00006399 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 142 | step 54300 |  ms/b 784.79 | train loss 0.00004818 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 142 | step 54350 |  ms/b 776.79 | train loss 0.00002239 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 142 | step 54400 |  ms/b 780.29 | train loss 0.00004110 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 142 | step 54450 |  ms/b 782.96 | train loss 0.00003225 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 142 | step 54500 |  ms/b 800.42 | train loss 0.00005439 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 142 | step 54550 |  ms/b 793.57 | train loss 0.00007004 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 142 | step 54600 |  ms/b 787.08 | train loss 0.00003549 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 143 | step 54650 |  ms/b 785.30 | train loss 0.00002740 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 143 | step 54700 |  ms/b 790.27 | train loss 0.00007547 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 143 | step 54750 |  ms/b 786.58 | train loss 0.00006371 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 143 | step 54800 |  ms/b 784.15 | train loss 0.00003442 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 143 | step 54850 |  ms/b 790.37 | train loss 0.00003088 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 143 | step 54900 |  ms/b 790.07 | train loss 0.00003663 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 143 | step 54950 |  ms/b 795.84 | train loss 0.00002685 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 143 | step 55000 |  ms/b 784.94 | train loss 0.00002838 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 144 | step 55050 |  ms/b 791.85 | train loss 0.00004851 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 144 | step 55100 |  ms/b 785.94 | train loss 0.00003681 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 144 | step 55150 |  ms/b 791.60 | train loss 0.00003780 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 144 | step 55200 |  ms/b 790.10 | train loss 0.00005354 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 144 | step 55250 |  ms/b 788.28 | train loss 0.00005709 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 144 | step 55300 |  ms/b 790.76 | train loss 0.00005595 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 144 | step 55350 |  ms/b 787.34 | train loss 0.00005036 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.14\ntotal_recall 12323\npredicted as zero 384676\ntotal ins num 395726\ntop1_acc 6523\nALL  : Theta 0.5426 | F1 0.5651 | AUC 0.5280\nIgnore ma_f1 0.5425 | input_theta 0.5426 test_result F1 0.5424 | AUC 0.4951\n| epoch 144 | time: 193.42s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 145 | step 55400 |  ms/b 4681.38 | train loss 0.00005576 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 145 | step 55450 |  ms/b 743.99 | train loss 0.00002738 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 145 | step 55500 |  ms/b 755.30 | train loss 0.00004801 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 145 | step 55550 |  ms/b 765.41 | train loss 0.00003253 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 145 | step 55600 |  ms/b 775.72 | train loss 0.00003782 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 145 | step 55650 |  ms/b 778.56 | train loss 0.00004547 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 145 | step 55700 |  ms/b 779.01 | train loss 0.00003170 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 145 | step 55750 |  ms/b 784.55 | train loss 0.00004544 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 146 | step 55800 |  ms/b 782.33 | train loss 0.00007018 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 146 | step 55850 |  ms/b 786.14 | train loss 0.00008341 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 146 | step 55900 |  ms/b 792.11 | train loss 0.00001934 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 146 | step 55950 |  ms/b 787.84 | train loss 0.00003521 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 146 | step 56000 |  ms/b 784.15 | train loss 0.00002255 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 146 | step 56050 |  ms/b 791.21 | train loss 0.00006521 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 146 | step 56100 |  ms/b 790.88 | train loss 0.00005112 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 146 | step 56150 |  ms/b 786.95 | train loss 0.00002979 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 147 | step 56200 |  ms/b 781.74 | train loss 0.00004236 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 147 | step 56250 |  ms/b 784.23 | train loss 0.00005271 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 147 | step 56300 |  ms/b 790.80 | train loss 0.00004345 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 147 | step 56350 |  ms/b 790.60 | train loss 0.00003818 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 147 | step 56400 |  ms/b 787.25 | train loss 0.00004466 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 147 | step 56450 |  ms/b 790.68 | train loss 0.00006801 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 147 | step 56500 |  ms/b 794.09 | train loss 0.00003717 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 148 | step 56550 |  ms/b 783.32 | train loss 0.00006111 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 148 | step 56600 |  ms/b 785.04 | train loss 0.00003867 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 148 | step 56650 |  ms/b 790.24 | train loss 0.00003375 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 148 | step 56700 |  ms/b 787.72 | train loss 0.00006380 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 148 | step 56750 |  ms/b 790.21 | train loss 0.00009705 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 148 | step 56800 |  ms/b 789.93 | train loss 0.00004302 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 148 | step 56850 |  ms/b 794.01 | train loss 0.00003403 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 148 | step 56900 |  ms/b 791.68 | train loss 0.00001940 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 149 | step 56950 |  ms/b 784.88 | train loss 0.00002033 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 149 | step 57000 |  ms/b 790.77 | train loss 0.00004033 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 149 | step 57050 |  ms/b 785.39 | train loss 0.00002635 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 149 | step 57100 |  ms/b 791.74 | train loss 0.00004894 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 149 | step 57150 |  ms/b 793.40 | train loss 0.00005775 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 149 | step 57200 |  ms/b 783.11 | train loss 0.00002500 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 149 | step 57250 |  ms/b 785.51 | train loss 0.00003916 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 149 | step 57300 |  ms/b 781.48 | train loss 0.00006190 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.21\ntotal_recall 12323\npredicted as zero 383295\ntotal ins num 395726\ntop1_acc 6845\nALL  : Theta 0.7017 | F1 0.5616 | AUC 0.5266\nIgnore ma_f1 0.5392 | input_theta 0.7017 test_result F1 0.5371 | AUC 0.4916\n| epoch 149 | time: 194.51s\n-----------------------------------------------------------------------------------------\n| epoch 150 | step 57350 |  ms/b 4631.73 | train loss 0.00004236 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 150 | step 57400 |  ms/b 748.32 | train loss 0.00002895 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 150 | step 57450 |  ms/b 764.58 | train loss 0.00001987 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 150 | step 57500 |  ms/b 774.59 | train loss 0.00005487 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 150 | step 57550 |  ms/b 774.61 | train loss 0.00004235 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 150 | step 57600 |  ms/b 781.58 | train loss 0.00003237 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 150 | step 57650 |  ms/b 789.14 | train loss 0.00003078 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 151 | step 57700 |  ms/b 782.93 | train loss 0.00002034 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 151 | step 57750 |  ms/b 788.95 | train loss 0.00002144 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 151 | step 57800 |  ms/b 794.33 | train loss 0.00003919 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 151 | step 57850 |  ms/b 786.18 | train loss 0.00002203 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 151 | step 57900 |  ms/b 788.61 | train loss 0.00001882 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 151 | step 57950 |  ms/b 783.30 | train loss 0.00001703 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 151 | step 58000 |  ms/b 792.31 | train loss 0.00006414 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 151 | step 58050 |  ms/b 792.08 | train loss 0.00005215 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 152 | step 58100 |  ms/b 787.76 | train loss 0.00002964 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 152 | step 58150 |  ms/b 785.68 | train loss 0.00001810 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 152 | step 58200 |  ms/b 792.22 | train loss 0.00002530 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 152 | step 58250 |  ms/b 789.01 | train loss 0.00005854 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 152 | step 58300 |  ms/b 787.54 | train loss 0.00003310 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 152 | step 58350 |  ms/b 795.73 | train loss 0.00003998 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 152 | step 58400 |  ms/b 786.66 | train loss 0.00001922 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 153 | step 58450 |  ms/b 787.47 | train loss 0.00002167 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 153 | step 58500 |  ms/b 786.05 | train loss 0.00001895 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 153 | step 58550 |  ms/b 788.04 | train loss 0.00002040 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 153 | step 58600 |  ms/b 786.06 | train loss 0.00002772 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 153 | step 58650 |  ms/b 792.12 | train loss 0.00003005 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 153 | step 58700 |  ms/b 784.69 | train loss 0.00002263 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 153 | step 58750 |  ms/b 788.97 | train loss 0.00002709 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 153 | step 58800 |  ms/b 798.09 | train loss 0.00003333 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 154 | step 58850 |  ms/b 783.29 | train loss 0.00002301 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 154 | step 58900 |  ms/b 790.99 | train loss 0.00002716 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 154 | step 58950 |  ms/b 791.69 | train loss 0.00003381 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 154 | step 59000 |  ms/b 791.78 | train loss 0.00005502 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 154 | step 59050 |  ms/b 789.29 | train loss 0.00003949 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 154 | step 59100 |  ms/b 787.96 | train loss 0.00003059 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 154 | step 59150 |  ms/b 793.32 | train loss 0.00004008 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 154 | step 59200 |  ms/b 787.99 | train loss 0.00004015 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.38\ntotal_recall 12323\npredicted as zero 383680\ntotal ins num 395726\ntop1_acc 6747\nALL  : Theta 0.5470 | F1 0.5592 | AUC 0.5233\nIgnore ma_f1 0.5361 | input_theta 0.5470 test_result F1 0.5338 | AUC 0.4885\n| epoch 154 | time: 193.51s\n-----------------------------------------------------------------------------------------\n| epoch 155 | step 59250 |  ms/b 4616.43 | train loss 0.00002770 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 155 | step 59300 |  ms/b 750.80 | train loss 0.00001931 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 155 | step 59350 |  ms/b 757.70 | train loss 0.00004067 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 155 | step 59400 |  ms/b 770.49 | train loss 0.00004858 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 155 | step 59450 |  ms/b 782.48 | train loss 0.00004315 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 155 | step 59500 |  ms/b 781.84 | train loss 0.00003039 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 155 | step 59550 |  ms/b 783.56 | train loss 0.00003170 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 156 | step 59600 |  ms/b 781.59 | train loss 0.00003080 | NA acc: 1.00 | not NA acc: 0.98  | tot acc: 0.99 \n| epoch 156 | step 59650 |  ms/b 785.45 | train loss 0.00004223 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 156 | step 59700 |  ms/b 792.74 | train loss 0.00004561 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 156 | step 59750 |  ms/b 783.93 | train loss 0.00005614 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 156 | step 59800 |  ms/b 786.59 | train loss 0.00004112 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 156 | step 59850 |  ms/b 790.88 | train loss 0.00011354 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 156 | step 59900 |  ms/b 785.91 | train loss 0.00002393 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 156 | step 59950 |  ms/b 784.69 | train loss 0.00001593 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 157 | step 60000 |  ms/b 786.75 | train loss 0.00006057 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 157 | step 60050 |  ms/b 788.11 | train loss 0.00002557 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 157 | step 60100 |  ms/b 790.15 | train loss 0.00005322 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 157 | step 60150 |  ms/b 788.26 | train loss 0.00001670 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 157 | step 60200 |  ms/b 788.97 | train loss 0.00014169 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 157 | step 60250 |  ms/b 789.41 | train loss 0.00003004 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 157 | step 60300 |  ms/b 789.38 | train loss 0.00004925 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 157 | step 60350 |  ms/b 792.86 | train loss 0.00002150 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 158 | step 60400 |  ms/b 783.86 | train loss 0.00002438 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 158 | step 60450 |  ms/b 784.75 | train loss 0.00003281 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 158 | step 60500 |  ms/b 785.08 | train loss 0.00001942 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 158 | step 60550 |  ms/b 784.30 | train loss 0.00002822 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 158 | step 60600 |  ms/b 788.31 | train loss 0.00003075 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 158 | step 60650 |  ms/b 788.38 | train loss 0.00001745 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 158 | step 60700 |  ms/b 788.30 | train loss 0.00005050 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 159 | step 60750 |  ms/b 782.68 | train loss 0.00001809 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 159 | step 60800 |  ms/b 791.23 | train loss 0.00003026 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 159 | step 60850 |  ms/b 784.66 | train loss 0.00001439 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 159 | step 60900 |  ms/b 793.75 | train loss 0.00004849 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 159 | step 60950 |  ms/b 788.52 | train loss 0.00002949 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 159 | step 61000 |  ms/b 788.97 | train loss 0.00001892 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 159 | step 61050 |  ms/b 789.22 | train loss 0.00001299 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 159 | step 61100 |  ms/b 791.70 | train loss 0.00001943 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 77.77\ntotal_recall 12323\npredicted as zero 384908\ntotal ins num 395726\ntop1_acc 6464\nALL  : Theta 0.4727 | F1 0.5673 | AUC 0.5293\nIgnore ma_f1 0.5441 | input_theta 0.4727 test_result F1 0.5441 | AUC 0.4953\n| epoch 159 | time: 192.02s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 160 | step 61150 |  ms/b 4625.27 | train loss 0.00001917 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 160 | step 61200 |  ms/b 745.16 | train loss 0.00001736 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 160 | step 61250 |  ms/b 760.97 | train loss 0.00001120 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 160 | step 61300 |  ms/b 768.27 | train loss 0.00003424 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 160 | step 61350 |  ms/b 778.20 | train loss 0.00003700 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 160 | step 61400 |  ms/b 780.16 | train loss 0.00002160 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 160 | step 61450 |  ms/b 772.66 | train loss 0.00002807 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 160 | step 61500 |  ms/b 784.88 | train loss 0.00003052 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 161 | step 61550 |  ms/b 785.90 | train loss 0.00003821 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 161 | step 61600 |  ms/b 786.20 | train loss 0.00003276 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 161 | step 61650 |  ms/b 789.11 | train loss 0.00004117 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 161 | step 61700 |  ms/b 788.13 | train loss 0.00001113 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 161 | step 61750 |  ms/b 788.70 | train loss 0.00002103 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 161 | step 61800 |  ms/b 783.53 | train loss 0.00001386 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 161 | step 61850 |  ms/b 788.79 | train loss 0.00002271 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 162 | step 61900 |  ms/b 782.41 | train loss 0.00001135 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 162 | step 61950 |  ms/b 788.68 | train loss 0.00003227 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 162 | step 62000 |  ms/b 783.34 | train loss 0.00002749 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 162 | step 62050 |  ms/b 789.06 | train loss 0.00001845 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 162 | step 62100 |  ms/b 790.71 | train loss 0.00001141 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 162 | step 62150 |  ms/b 789.99 | train loss 0.00002701 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 162 | step 62200 |  ms/b 788.93 | train loss 0.00001809 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 162 | step 62250 |  ms/b 786.35 | train loss 0.00001318 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 163 | step 62300 |  ms/b 787.05 | train loss 0.00001840 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 163 | step 62350 |  ms/b 790.40 | train loss 0.00001868 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 163 | step 62400 |  ms/b 790.08 | train loss 0.00002816 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 163 | step 62450 |  ms/b 791.12 | train loss 0.00000701 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 163 | step 62500 |  ms/b 789.82 | train loss 0.00003666 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 163 | step 62550 |  ms/b 791.20 | train loss 0.00002813 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 163 | step 62600 |  ms/b 791.14 | train loss 0.00002775 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 164 | step 62650 |  ms/b 784.87 | train loss 0.00000909 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 164 | step 62700 |  ms/b 784.84 | train loss 0.00000894 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 164 | step 62750 |  ms/b 785.72 | train loss 0.00001539 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 164 | step 62800 |  ms/b 783.03 | train loss 0.00001339 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 164 | step 62850 |  ms/b 789.74 | train loss 0.00001820 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 164 | step 62900 |  ms/b 785.96 | train loss 0.00002242 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 164 | step 62950 |  ms/b 784.63 | train loss 0.00001529 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 164 | step 63000 |  ms/b 784.42 | train loss 0.00001193 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.30\ntotal_recall 12323\npredicted as zero 384260\ntotal ins num 395726\ntop1_acc 6605\nALL  : Theta 0.4582 | F1 0.5638 | AUC 0.5281\nIgnore ma_f1 0.5409 | input_theta 0.4582 test_result F1 0.5391 | AUC 0.4928\n| epoch 164 | time: 192.60s\n-----------------------------------------------------------------------------------------\n| epoch 165 | step 63050 |  ms/b 4621.62 | train loss 0.00002161 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 165 | step 63100 |  ms/b 737.86 | train loss 0.00001700 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 165 | step 63150 |  ms/b 752.29 | train loss 0.00002540 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 165 | step 63200 |  ms/b 770.02 | train loss 0.00001445 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 165 | step 63250 |  ms/b 773.74 | train loss 0.00002561 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 165 | step 63300 |  ms/b 781.51 | train loss 0.00001586 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 165 | step 63350 |  ms/b 778.52 | train loss 0.00004917 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 165 | step 63400 |  ms/b 785.67 | train loss 0.00004094 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 166 | step 63450 |  ms/b 781.33 | train loss 0.00004236 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 166 | step 63500 |  ms/b 789.79 | train loss 0.00002770 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 166 | step 63550 |  ms/b 792.42 | train loss 0.00002988 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 166 | step 63600 |  ms/b 785.62 | train loss 0.00001388 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 166 | step 63650 |  ms/b 790.72 | train loss 0.00002988 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 166 | step 63700 |  ms/b 789.07 | train loss 0.00003771 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 166 | step 63750 |  ms/b 787.28 | train loss 0.00002377 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 167 | step 63800 |  ms/b 786.16 | train loss 0.00001216 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 167 | step 63850 |  ms/b 785.74 | train loss 0.00001842 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 167 | step 63900 |  ms/b 783.11 | train loss 0.00008501 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 167 | step 63950 |  ms/b 790.95 | train loss 0.00001397 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 167 | step 64000 |  ms/b 791.54 | train loss 0.00002048 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 167 | step 64050 |  ms/b 791.02 | train loss 0.00001742 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 167 | step 64100 |  ms/b 788.52 | train loss 0.00001213 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 167 | step 64150 |  ms/b 792.23 | train loss 0.00002756 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 168 | step 64200 |  ms/b 783.51 | train loss 0.00002262 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 168 | step 64250 |  ms/b 789.43 | train loss 0.00001920 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 168 | step 64300 |  ms/b 788.61 | train loss 0.00003143 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 168 | step 64350 |  ms/b 785.79 | train loss 0.00002070 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 168 | step 64400 |  ms/b 791.50 | train loss 0.00001930 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 168 | step 64450 |  ms/b 790.95 | train loss 0.00001369 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 168 | step 64500 |  ms/b 786.17 | train loss 0.00000865 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 168 | step 64550 |  ms/b 788.60 | train loss 0.00001668 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 169 | step 64600 |  ms/b 786.45 | train loss 0.00000924 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 169 | step 64650 |  ms/b 790.50 | train loss 0.00001167 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 169 | step 64700 |  ms/b 784.65 | train loss 0.00002322 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 169 | step 64750 |  ms/b 786.30 | train loss 0.00001571 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 169 | step 64800 |  ms/b 789.24 | train loss 0.00002928 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 169 | step 64850 |  ms/b 786.22 | train loss 0.00000925 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 169 | step 64900 |  ms/b 783.24 | train loss 0.00001511 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.24\ntotal_recall 12323\npredicted as zero 384056\ntotal ins num 395726\ntop1_acc 6702\nALL  : Theta 0.4682 | F1 0.5664 | AUC 0.5305\nIgnore ma_f1 0.5440 | input_theta 0.4682 test_result F1 0.5421 | AUC 0.4976\n| epoch 169 | time: 193.23s\n-----------------------------------------------------------------------------------------\n| epoch 170 | step 64950 |  ms/b 4643.37 | train loss 0.00002856 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 170 | step 65000 |  ms/b 736.08 | train loss 0.00001041 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 170 | step 65050 |  ms/b 753.28 | train loss 0.00001348 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 170 | step 65100 |  ms/b 770.33 | train loss 0.00000858 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 170 | step 65150 |  ms/b 766.42 | train loss 0.00000677 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 170 | step 65200 |  ms/b 778.74 | train loss 0.00001000 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 170 | step 65250 |  ms/b 778.32 | train loss 0.00003087 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 170 | step 65300 |  ms/b 784.87 | train loss 0.00000876 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 171 | step 65350 |  ms/b 781.25 | train loss 0.00002692 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 171 | step 65400 |  ms/b 784.31 | train loss 0.00001279 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 171 | step 65450 |  ms/b 788.87 | train loss 0.00001142 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 171 | step 65500 |  ms/b 787.86 | train loss 0.00001941 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 171 | step 65550 |  ms/b 791.99 | train loss 0.00000828 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 171 | step 65600 |  ms/b 786.76 | train loss 0.00001523 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 171 | step 65650 |  ms/b 788.51 | train loss 0.00001016 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 171 | step 65700 |  ms/b 789.47 | train loss 0.00001010 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 172 | step 65750 |  ms/b 787.47 | train loss 0.00001491 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 172 | step 65800 |  ms/b 789.39 | train loss 0.00002884 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 172 | step 65850 |  ms/b 792.42 | train loss 0.00004065 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 172 | step 65900 |  ms/b 785.16 | train loss 0.00001408 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 172 | step 65950 |  ms/b 790.38 | train loss 0.00003912 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 172 | step 66000 |  ms/b 789.09 | train loss 0.00001737 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 172 | step 66050 |  ms/b 789.91 | train loss 0.00001922 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 173 | step 66100 |  ms/b 785.93 | train loss 0.00001022 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 173 | step 66150 |  ms/b 788.41 | train loss 0.00000975 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 173 | step 66200 |  ms/b 783.68 | train loss 0.00004105 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 173 | step 66250 |  ms/b 792.40 | train loss 0.00002339 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 173 | step 66300 |  ms/b 784.89 | train loss 0.00001197 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 173 | step 66350 |  ms/b 791.59 | train loss 0.00000948 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 173 | step 66400 |  ms/b 786.97 | train loss 0.00001978 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 173 | step 66450 |  ms/b 787.20 | train loss 0.00000697 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 174 | step 66500 |  ms/b 785.13 | train loss 0.00000606 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 174 | step 66550 |  ms/b 790.95 | train loss 0.00002633 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 174 | step 66600 |  ms/b 790.79 | train loss 0.00000867 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 174 | step 66650 |  ms/b 793.77 | train loss 0.00001315 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 174 | step 66700 |  ms/b 787.19 | train loss 0.00002346 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 174 | step 66750 |  ms/b 787.45 | train loss 0.00001846 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 174 | step 66800 |  ms/b 787.81 | train loss 0.00000858 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 174 | step 66850 |  ms/b 783.90 | train loss 0.00001071 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.41\ntotal_recall 12323\npredicted as zero 384720\ntotal ins num 395726\ntop1_acc 6537\nALL  : Theta 0.4969 | F1 0.5681 | AUC 0.5335\nIgnore ma_f1 0.5458 | input_theta 0.4969 test_result F1 0.5449 | AUC 0.4999\n| epoch 174 | time: 193.71s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 175 | step 66900 |  ms/b 4645.44 | train loss 0.00000980 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 175 | step 66950 |  ms/b 750.88 | train loss 0.00000994 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 175 | step 67000 |  ms/b 762.97 | train loss 0.00001423 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 175 | step 67050 |  ms/b 770.80 | train loss 0.00001847 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 175 | step 67100 |  ms/b 776.99 | train loss 0.00000654 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 175 | step 67150 |  ms/b 786.49 | train loss 0.00001717 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 175 | step 67200 |  ms/b 791.63 | train loss 0.00001204 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 176 | step 67250 |  ms/b 780.19 | train loss 0.00001504 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.98 \n| epoch 176 | step 67300 |  ms/b 787.46 | train loss 0.00001370 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 176 | step 67350 |  ms/b 785.67 | train loss 0.00000859 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 176 | step 67400 |  ms/b 796.37 | train loss 0.00001509 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 176 | step 67450 |  ms/b 785.37 | train loss 0.00001378 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 176 | step 67500 |  ms/b 786.02 | train loss 0.00001211 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 176 | step 67550 |  ms/b 788.50 | train loss 0.00001545 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 176 | step 67600 |  ms/b 787.80 | train loss 0.00000825 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 177 | step 67650 |  ms/b 781.23 | train loss 0.00000737 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 177 | step 67700 |  ms/b 789.48 | train loss 0.00000757 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 177 | step 67750 |  ms/b 791.90 | train loss 0.00001120 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 177 | step 67800 |  ms/b 779.77 | train loss 0.00000626 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 177 | step 67850 |  ms/b 781.93 | train loss 0.00001697 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 177 | step 67900 |  ms/b 786.96 | train loss 0.00001573 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 177 | step 67950 |  ms/b 784.18 | train loss 0.00000663 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 178 | step 68000 |  ms/b 783.74 | train loss 0.00000674 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 178 | step 68050 |  ms/b 789.07 | train loss 0.00001023 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 178 | step 68100 |  ms/b 783.80 | train loss 0.00000917 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 178 | step 68150 |  ms/b 783.23 | train loss 0.00000883 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 178 | step 68200 |  ms/b 783.97 | train loss 0.00000777 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 178 | step 68250 |  ms/b 781.88 | train loss 0.00002046 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 178 | step 68300 |  ms/b 782.57 | train loss 0.00000765 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 178 | step 68350 |  ms/b 784.70 | train loss 0.00000399 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 179 | step 68400 |  ms/b 779.19 | train loss 0.00000832 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 179 | step 68450 |  ms/b 783.34 | train loss 0.00000527 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 179 | step 68500 |  ms/b 785.01 | train loss 0.00000928 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 179 | step 68550 |  ms/b 786.85 | train loss 0.00001016 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 179 | step 68600 |  ms/b 785.69 | train loss 0.00001294 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 179 | step 68650 |  ms/b 782.59 | train loss 0.00001576 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 179 | step 68700 |  ms/b 782.38 | train loss 0.00000844 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 179 | step 68750 |  ms/b 781.04 | train loss 0.00001323 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.27\ntotal_recall 12323\npredicted as zero 385418\ntotal ins num 395726\ntop1_acc 6317\nALL  : Theta 0.2676 | F1 0.5689 | AUC 0.5327\nIgnore ma_f1 0.5463 | input_theta 0.2676 test_result F1 0.5456 | AUC 0.4999\n| epoch 179 | time: 193.31s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 180 | step 68800 |  ms/b 4638.26 | train loss 0.00000656 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 180 | step 68850 |  ms/b 752.60 | train loss 0.00000665 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 180 | step 68900 |  ms/b 764.06 | train loss 0.00001644 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 180 | step 68950 |  ms/b 765.01 | train loss 0.00000798 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 180 | step 69000 |  ms/b 772.78 | train loss 0.00000653 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 180 | step 69050 |  ms/b 781.47 | train loss 0.00001264 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 180 | step 69100 |  ms/b 779.07 | train loss 0.00000656 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 181 | step 69150 |  ms/b 787.53 | train loss 0.00002583 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 181 | step 69200 |  ms/b 789.86 | train loss 0.00001689 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 181 | step 69250 |  ms/b 789.10 | train loss 0.00000746 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 181 | step 69300 |  ms/b 789.48 | train loss 0.00000707 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 181 | step 69350 |  ms/b 790.00 | train loss 0.00000854 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 181 | step 69400 |  ms/b 786.17 | train loss 0.00000645 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 181 | step 69450 |  ms/b 791.80 | train loss 0.00001849 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 181 | step 69500 |  ms/b 788.81 | train loss 0.00001152 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 182 | step 69550 |  ms/b 782.32 | train loss 0.00001391 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 182 | step 69600 |  ms/b 787.35 | train loss 0.00000865 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 182 | step 69650 |  ms/b 785.69 | train loss 0.00000711 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 182 | step 69700 |  ms/b 791.26 | train loss 0.00000628 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 182 | step 69750 |  ms/b 787.15 | train loss 0.00000475 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 182 | step 69800 |  ms/b 792.11 | train loss 0.00011564 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 182 | step 69850 |  ms/b 789.03 | train loss 0.00000944 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 182 | step 69900 |  ms/b 789.25 | train loss 0.00001543 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 183 | step 69950 |  ms/b 784.09 | train loss 0.00000481 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 183 | step 70000 |  ms/b 790.63 | train loss 0.00001562 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 183 | step 70050 |  ms/b 791.62 | train loss 0.00002424 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 183 | step 70100 |  ms/b 791.11 | train loss 0.00000571 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 183 | step 70150 |  ms/b 789.94 | train loss 0.00000955 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 183 | step 70200 |  ms/b 791.39 | train loss 0.00000586 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 183 | step 70250 |  ms/b 781.71 | train loss 0.00000783 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 184 | step 70300 |  ms/b 779.92 | train loss 0.00000686 | NA acc: 1.00 | not NA acc: 0.98  | tot acc: 0.99 \n| epoch 184 | step 70350 |  ms/b 785.17 | train loss 0.00000581 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 184 | step 70400 |  ms/b 778.46 | train loss 0.00000536 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 184 | step 70450 |  ms/b 787.67 | train loss 0.00001589 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 184 | step 70500 |  ms/b 780.99 | train loss 0.00000600 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 184 | step 70550 |  ms/b 779.95 | train loss 0.00000468 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 184 | step 70600 |  ms/b 788.18 | train loss 0.00002479 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 184 | step 70650 |  ms/b 781.22 | train loss 0.00001398 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 77.90\ntotal_recall 12323\npredicted as zero 384542\ntotal ins num 395726\ntop1_acc 6582\nALL  : Theta 0.6389 | F1 0.5693 | AUC 0.5342\nIgnore ma_f1 0.5469 | input_theta 0.6389 test_result F1 0.5467 | AUC 0.5004\n| epoch 184 | time: 193.21s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 185 | step 70700 |  ms/b 4638.40 | train loss 0.00000315 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 185 | step 70750 |  ms/b 743.31 | train loss 0.00000999 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 185 | step 70800 |  ms/b 756.83 | train loss 0.00000626 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 185 | step 70850 |  ms/b 771.32 | train loss 0.00001638 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 185 | step 70900 |  ms/b 774.81 | train loss 0.00001150 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 185 | step 70950 |  ms/b 775.77 | train loss 0.00000541 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 185 | step 71000 |  ms/b 783.25 | train loss 0.00001286 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 185 | step 71050 |  ms/b 782.13 | train loss 0.00007065 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 186 | step 71100 |  ms/b 780.02 | train loss 0.00000551 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 186 | step 71150 |  ms/b 785.37 | train loss 0.00000853 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 186 | step 71200 |  ms/b 792.03 | train loss 0.00000415 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 186 | step 71250 |  ms/b 788.10 | train loss 0.00001195 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 186 | step 71300 |  ms/b 788.66 | train loss 0.00000993 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 186 | step 71350 |  ms/b 783.97 | train loss 0.00000621 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 186 | step 71400 |  ms/b 788.05 | train loss 0.00001545 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 187 | step 71450 |  ms/b 786.68 | train loss 0.00000948 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 187 | step 71500 |  ms/b 789.03 | train loss 0.00000547 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 187 | step 71550 |  ms/b 789.21 | train loss 0.00001260 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 187 | step 71600 |  ms/b 784.07 | train loss 0.00000469 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 187 | step 71650 |  ms/b 797.01 | train loss 0.00000590 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 187 | step 71700 |  ms/b 788.75 | train loss 0.00000814 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 187 | step 71750 |  ms/b 786.42 | train loss 0.00001777 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 187 | step 71800 |  ms/b 792.98 | train loss 0.00000801 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 188 | step 71850 |  ms/b 786.14 | train loss 0.00000497 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 188 | step 71900 |  ms/b 793.03 | train loss 0.00000432 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 188 | step 71950 |  ms/b 790.78 | train loss 0.00001255 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 188 | step 72000 |  ms/b 793.13 | train loss 0.00000635 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 188 | step 72050 |  ms/b 788.82 | train loss 0.00000790 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 188 | step 72100 |  ms/b 788.02 | train loss 0.00000565 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 188 | step 72150 |  ms/b 790.51 | train loss 0.00000533 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 189 | step 72200 |  ms/b 784.35 | train loss 0.00000387 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 189 | step 72250 |  ms/b 792.17 | train loss 0.00000479 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 189 | step 72300 |  ms/b 787.93 | train loss 0.00002612 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 189 | step 72350 |  ms/b 793.16 | train loss 0.00000504 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 189 | step 72400 |  ms/b 788.62 | train loss 0.00001428 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 189 | step 72450 |  ms/b 786.07 | train loss 0.00000448 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 189 | step 72500 |  ms/b 791.46 | train loss 0.00000444 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 189 | step 72550 |  ms/b 794.69 | train loss 0.00000983 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.06\ntotal_recall 12323\npredicted as zero 385081\ntotal ins num 395726\ntop1_acc 6404\nALL  : Theta 0.4008 | F1 0.5697 | AUC 0.5341\nIgnore ma_f1 0.5472 | input_theta 0.4008 test_result F1 0.5470 | AUC 0.5006\n| epoch 189 | time: 192.39s\n-----------------------------------------------------------------------------------------\nStoring result...\n| epoch 190 | step 72600 |  ms/b 4631.30 | train loss 0.00000523 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 190 | step 72650 |  ms/b 744.09 | train loss 0.00000929 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 190 | step 72700 |  ms/b 763.76 | train loss 0.00000967 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 190 | step 72750 |  ms/b 762.58 | train loss 0.00000387 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 190 | step 72800 |  ms/b 768.69 | train loss 0.00000402 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 190 | step 72850 |  ms/b 782.45 | train loss 0.00000806 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 190 | step 72900 |  ms/b 790.46 | train loss 0.00000743 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 190 | step 72950 |  ms/b 787.74 | train loss 0.00000797 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 191 | step 73000 |  ms/b 787.88 | train loss 0.00000452 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 191 | step 73050 |  ms/b 788.83 | train loss 0.00000460 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 191 | step 73100 |  ms/b 786.39 | train loss 0.00000411 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 191 | step 73150 |  ms/b 787.07 | train loss 0.00000787 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 191 | step 73200 |  ms/b 786.31 | train loss 0.00001948 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 191 | step 73250 |  ms/b 791.84 | train loss 0.00000334 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 191 | step 73300 |  ms/b 786.61 | train loss 0.00000838 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 192 | step 73350 |  ms/b 786.58 | train loss 0.00000298 | NA acc: 1.00 | not NA acc: 0.95  | tot acc: 0.98 \n| epoch 192 | step 73400 |  ms/b 788.29 | train loss 0.00000607 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 192 | step 73450 |  ms/b 785.60 | train loss 0.00000337 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 192 | step 73500 |  ms/b 781.05 | train loss 0.00000335 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 192 | step 73550 |  ms/b 783.44 | train loss 0.00000744 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 192 | step 73600 |  ms/b 784.37 | train loss 0.00000446 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 192 | step 73650 |  ms/b 785.70 | train loss 0.00000323 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 192 | step 73700 |  ms/b 787.80 | train loss 0.00000248 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 193 | step 73750 |  ms/b 780.92 | train loss 0.00000452 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 193 | step 73800 |  ms/b 782.53 | train loss 0.00000368 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 193 | step 73850 |  ms/b 781.20 | train loss 0.00000423 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 193 | step 73900 |  ms/b 792.31 | train loss 0.00000892 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 193 | step 73950 |  ms/b 785.43 | train loss 0.00000249 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 193 | step 74000 |  ms/b 784.70 | train loss 0.00000372 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 193 | step 74050 |  ms/b 787.67 | train loss 0.00002052 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 193 | step 74100 |  ms/b 792.23 | train loss 0.00000815 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 194 | step 74150 |  ms/b 782.39 | train loss 0.00000377 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 194 | step 74200 |  ms/b 783.90 | train loss 0.00000409 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 194 | step 74250 |  ms/b 786.63 | train loss 0.00000519 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 194 | step 74300 |  ms/b 784.86 | train loss 0.00000222 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 194 | step 74350 |  ms/b 788.86 | train loss 0.00000302 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 194 | step 74400 |  ms/b 788.35 | train loss 0.00000942 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 194 | step 74450 |  ms/b 784.88 | train loss 0.00000235 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.84\ntotal_recall 12323\npredicted as zero 385100\ntotal ins num 395726\ntop1_acc 6408\nALL  : Theta 0.5017 | F1 0.5694 | AUC 0.5344\nIgnore ma_f1 0.5474 | input_theta 0.5017 test_result F1 0.5473 | AUC 0.5015\n| epoch 194 | time: 209.62s\n-----------------------------------------------------------------------------------------\n| epoch 195 | step 74500 |  ms/b 4960.25 | train loss 0.00000336 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 195 | step 74550 |  ms/b 739.90 | train loss 0.00001156 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 195 | step 74600 |  ms/b 756.93 | train loss 0.00000515 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 195 | step 74650 |  ms/b 761.86 | train loss 0.00000397 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 195 | step 74700 |  ms/b 768.91 | train loss 0.00001324 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 195 | step 74750 |  ms/b 774.14 | train loss 0.00000204 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 195 | step 74800 |  ms/b 783.24 | train loss 0.00000708 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 195 | step 74850 |  ms/b 786.51 | train loss 0.00000234 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 196 | step 74900 |  ms/b 788.92 | train loss 0.00002009 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 196 | step 74950 |  ms/b 783.75 | train loss 0.00000560 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 196 | step 75000 |  ms/b 789.99 | train loss 0.00001265 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 196 | step 75050 |  ms/b 784.98 | train loss 0.00000697 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 196 | step 75100 |  ms/b 787.49 | train loss 0.00000671 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 196 | step 75150 |  ms/b 787.70 | train loss 0.00000367 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 196 | step 75200 |  ms/b 786.03 | train loss 0.00000382 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 196 | step 75250 |  ms/b 785.59 | train loss 0.00000688 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 197 | step 75300 |  ms/b 780.21 | train loss 0.00000289 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 197 | step 75350 |  ms/b 790.45 | train loss 0.00000288 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 197 | step 75400 |  ms/b 785.46 | train loss 0.00000516 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 197 | step 75450 |  ms/b 791.85 | train loss 0.00000509 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 197 | step 75500 |  ms/b 782.89 | train loss 0.00000932 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 197 | step 75550 |  ms/b 790.10 | train loss 0.00000405 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 197 | step 75600 |  ms/b 787.67 | train loss 0.00000483 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 198 | step 75650 |  ms/b 780.27 | train loss 0.00000534 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 198 | step 75700 |  ms/b 779.55 | train loss 0.00000337 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 198 | step 75750 |  ms/b 788.14 | train loss 0.00000366 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 198 | step 75800 |  ms/b 781.07 | train loss 0.00000368 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 198 | step 75850 |  ms/b 781.75 | train loss 0.00000266 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 198 | step 75900 |  ms/b 780.00 | train loss 0.00000520 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 198 | step 75950 |  ms/b 787.48 | train loss 0.00000501 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 198 | step 76000 |  ms/b 780.16 | train loss 0.00000246 | NA acc: 1.00 | not NA acc: 0.96  | tot acc: 0.99 \n| epoch 199 | step 76050 |  ms/b 786.06 | train loss 0.00000485 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 199 | step 76100 |  ms/b 788.69 | train loss 0.00000480 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 199 | step 76150 |  ms/b 785.26 | train loss 0.00000286 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 199 | step 76200 |  ms/b 790.11 | train loss 0.00000590 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 199 | step 76250 |  ms/b 783.48 | train loss 0.00000449 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 199 | step 76300 |  ms/b 781.90 | train loss 0.00000275 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 199 | step 76350 |  ms/b 788.26 | train loss 0.00000281 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n| epoch 199 | step 76400 |  ms/b 776.91 | train loss 0.00000365 | NA acc: 1.00 | not NA acc: 0.97  | tot acc: 0.99 \n-----------------------------------------------------------------------------------------\n| step   1 | time: 78.11\ntotal_recall 12323\npredicted as zero 385121\ntotal ins num 395726\ntop1_acc 6388\nALL  : Theta 0.4568 | F1 0.5696 | AUC 0.5337\nIgnore ma_f1 0.5475 | input_theta 0.4568 test_result F1 0.5474 | AUC 0.5007\n| epoch 199 | time: 193.05s\n-----------------------------------------------------------------------------------------\n-----------------------------------------------------------------------------------------\n| step   1 | time: 77.32\ntotal_recall 12323\npredicted as zero 385121\ntotal ins num 395726\ntop1_acc 6388\nALL  : Theta 0.4568 | F1 0.5696 | AUC 0.5337\nIgnore ma_f1 0.5475 | input_theta 0.4568 test_result F1 0.5474 | AUC 0.5007\n| epoch 199 | time: 193.00s\n-----------------------------------------------------------------------------------------\nFinish training\nBest epoch = 189 | F1 = 0.569697 AUC = 0.500641\n"}],"execution_count":3}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"papermill":{"default_parameters":{},"duration":67757.62184,"end_time":"2024-06-17T08:54:03.608117","environment_variables":{},"exception":null,"input_path":"s3://kesci-lab-ipynb/666eee9e97754e13967f4d15.ipynb","output_path":"s3://kesci-datasets-uploaded-files/mpijob-outputs/666eee9e97754e13967f4d15/0.ipynb","parameters":{},"start_time":"2024-06-16T14:04:45.986277","version":"2.3.1"}},"nbformat":4,"nbformat_minor":5}